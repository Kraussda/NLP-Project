{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5e79fd1",
   "metadata": {},
   "source": [
    "Code adapated from https://towardsdatascience.com/how-to-use-the-reddit-api-in-python-5e05ddfd1e5c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1fc02e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a10bff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use this function to convert responses to dataframes\n",
    "def df_from_response(res):\n",
    "    # initialize temp dataframe for batch of data in response\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # loop through each post pulled from res and append to df\n",
    "    for post in res.json()['data']['children']:\n",
    "        df = df.append({\n",
    "            'subreddit': post['data']['subreddit'],\n",
    "            'title': post['data']['title'],\n",
    "            'selftext': post['data']['selftext'],\n",
    "            'upvote_ratio': post['data']['upvote_ratio'],\n",
    "            'ups': post['data']['ups'],\n",
    "            'downs': post['data']['downs'],\n",
    "            'score': post['data']['score'],\n",
    "            'link_flair_css_class': post['data']['link_flair_css_class'],\n",
    "            'created_utc': datetime.fromtimestamp(post['data']['created_utc']).strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "            'id': post['data']['id'],\n",
    "            'kind': post['kind']\n",
    "        }, ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a332f864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2df77ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # note that CLIENT_ID refers to 'personal use script' and SECRET_TOKEN to 'token'\n",
    "# auth = requests.auth.HTTPBasicAuth('fPcc4PaCv-PIfyJR7_syRQ', 'jSoX7iF9c9EKxUHw8A4A1DFRch5Y6Q')\n",
    "\n",
    "# # here we pass our login method (password), username, and password\n",
    "# data = {'grant_type': 'password',\n",
    "#         'username': 'lollersauce914',\n",
    "#         'password': 'kittiesarecute1!'}\n",
    "\n",
    "# # setup our header info, which gives reddit a brief description of our app\n",
    "# headers = {'User-Agent': 'MyBot/0.0.1'}\n",
    "\n",
    "# # send our request for an OAuth token\n",
    "# res = requests.post('https://www.reddit.com/api/v1/access_token',\n",
    "#                     auth=auth, data=data, headers=headers)\n",
    "\n",
    "# # convert response to JSON and pull access_token value\n",
    "# TOKEN = res.json()['access_token']\n",
    "\n",
    "# # add authorization to our headers dictionary\n",
    "# headers = {**headers, **{'Authorization': f\"bearer {TOKEN}\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "10f753fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize dataframe and parameters for pulling data in loop\n",
    "# data = pd.DataFrame()\n",
    "# params = {'limit': 100}\n",
    "\n",
    "# # loop through 10 times (returning 1K posts)\n",
    "# for i in range(10):\n",
    "#     # make request\n",
    "#     res = requests.get(\"https://oauth.reddit.com/r/gme/new\",\n",
    "#                        headers=headers,\n",
    "#                        params=params)\n",
    "\n",
    "#     # get dataframe from response\n",
    "#     new_df = df_from_response(res)\n",
    "#     # take the final row (oldest entry)\n",
    "#     row = new_df.iloc[len(new_df)-1]\n",
    "#     # create fullname\n",
    "#     fullname = row['kind'] + '_' + row['id']\n",
    "#     # add/update fullname in params\n",
    "#     params['after'] = fullname\n",
    "    \n",
    "#     # append new_df to data\n",
    "#     data = data.append(new_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "424210b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ofndn2'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data.head()\n",
    "# row = data.iloc[1]\n",
    "# # create fullname\n",
    "# fullname = row['id']\n",
    "\n",
    "# fullname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4a348e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://oauth.reddit.com/r/gme/comments/t3_ofjwds/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Not Found', 'error': 404}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(f\"https://oauth.reddit.com/r/gme/comments/{fullname}/\")\n",
    "# test = requests.get(f\"https://oauth.reddit.com/r/gme/comments/{fullname}/\",\n",
    "#                        headers=headers)\n",
    "\n",
    "# test.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a7b45001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# link = \"https://api.pushshift.io/reddit/search/submission/?subreddit=gme&sort=desc&sort_type=created_utc&after=1609480800&before=1625115600&size=100\"\n",
    "# res = requests.get(link)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb671ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7429127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use this function to convert responses to dataframes\n",
    "def df_from_response(res):\n",
    "    # initialize temp dataframe for batch of data in response\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # loop through each post pulled from res and append to df\n",
    "    for post in res.json()['data']:\n",
    "        try:\n",
    "            df = df.append({\n",
    "                'subreddit': post['subreddit'],\n",
    "                'title': post['title'],\n",
    "                'selftext': post['selftext'],\n",
    "                'upvote_ratio': post['upvote_ratio'],\n",
    "                'created_utc': datetime.fromtimestamp(post['created_utc']).strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "                'utc_raw': post['created_utc'],\n",
    "                'id': post['id'],\n",
    "                'kind': 't3'\n",
    "            }, ignore_index=True)\n",
    "        #catch missing self_text\n",
    "        except:\n",
    "            df = df.append({\n",
    "                'subreddit': post['subreddit'],\n",
    "                'title': post['title'],\n",
    "                'selftext': '',\n",
    "                'upvote_ratio': post['upvote_ratio'],\n",
    "                'created_utc': datetime.fromtimestamp(post['created_utc']).strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "                'utc_raw': post['created_utc'],\n",
    "                'id': post['id'],\n",
    "                'kind': 't3'\n",
    "            }, ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e52e8ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting on month 06.\n",
      "starting on month 06.\n",
      "starting on month 06.\n",
      "starting on month 06.\n",
      "starting on month 06.\n",
      "starting on month 06.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-146-1a4f38b92e7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mnew_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_from_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# take the final row (oldest entry)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;31m# get earliest date\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mbefore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'utc_raw'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[1;31m# validate the location\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1442\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1443\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1444\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1446\u001b[0m     \u001b[1;31m# -------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "# get all posts from June on back to Jan 1 2021\n",
    "before = 1625115600\n",
    "data = pd.DataFrame()\n",
    "newest_month = 0\n",
    "\n",
    "while before > 1609480800:\n",
    "    # make request\n",
    "    res = requests.get(f\"https://api.pushshift.io/reddit/search/submission/?subreddit=gme&sort=desc&sort_type=created_utc&after=1609480800&before={before}&size=100\")\n",
    "    # check for empty set\n",
    "    if res.text == '{\\n    \"data\": []\\n}':\n",
    "        break\n",
    "    # get dataframe from response\n",
    "    new_df = df_from_response(res)\n",
    "    # take the final row (oldest entry)\n",
    "    row = new_df.iloc[len(new_df)-1]\n",
    "    # get earliest date\n",
    "    before = int(row['utc_raw'])\n",
    "    # show where we're at\n",
    "    if datetime.fromtimestamp(before).strftime('%m') != newest_month:\n",
    "        newest_month = datetime.fromtimestamp(before).strftime('%m')\n",
    "        print(f\"starting on month {datetime.fromtimestamp(before).strftime('%m')}.\")\n",
    "    \n",
    "    # append new_df to data\n",
    "    data = data.append(new_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "df80d3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(r\"C:\\Users\\Daniel\\Documents\\NLP Class\\Project\\gme_posts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57583426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use this function to convert responses to dataframes\n",
    "def df_from_comment(res):\n",
    "    # initialize temp dataframe for batch of data in response\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # loop through each post pulled from res and append to df\n",
    "    for post in res.json()['data']:\n",
    "        try:\n",
    "            df = df.append({\n",
    "                'subreddit': post['subreddit'],\n",
    "                'parent': post['parent_id'],\n",
    "                'body': post['body'],\n",
    "                'created_utc': datetime.fromtimestamp(post['created_utc']).strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "                'utc_raw': post['created_utc'],\n",
    "                'id': post['id'],\n",
    "                'kind': 't2'\n",
    "            }, ignore_index=True)\n",
    "        #catch missing body\n",
    "        except:\n",
    "            df = df.append({\n",
    "                'subreddit': post['subreddit'],\n",
    "                'parent': post['parent_id'],\n",
    "                'body': '',\n",
    "                'created_utc': datetime.fromtimestamp(post['created_utc']).strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "                'utc_raw': post['created_utc'],\n",
    "                'id': post['id'],\n",
    "                'kind': 't2'\n",
    "            }, ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "87eab33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting on month 06.\n",
      "starting on month 05.\n"
     ]
    }
   ],
   "source": [
    "# get all posts from June on back to Jan 1 2021\n",
    "# June\n",
    "before = 1625115600\n",
    "june_comments = pd.DataFrame()\n",
    "newest_month = 0\n",
    "\n",
    "while before > 1622523600:\n",
    "    # make request\n",
    "    time.sleep(3)\n",
    "    res = requests.get(f\"https://api.pushshift.io/reddit/search/comment/?subreddit=gme&sort=desc&sort_type=created_utc&after=1609480800&before={before}&size=500\")\n",
    "    if res.ok == False and res.status_code >= 500:\n",
    "        continue\n",
    "    if res.ok == False and res.status_code < 500:\n",
    "        print(\"too many requests\")\n",
    "        break\n",
    "    # check for empty set\n",
    "    if res.text == '{\\n    \"data\": []\\n}':\n",
    "        continue\n",
    "    # get dataframe from response\n",
    "    new_df = df_from_comment(res)\n",
    "    # take the final row (oldest entry)\n",
    "    row = new_df.iloc[len(new_df)-1]\n",
    "    # get earliest date\n",
    "    before = int(row['utc_raw'])\n",
    "    # show where we're at\n",
    "    if datetime.fromtimestamp(before).strftime('%m') != newest_month:\n",
    "        newest_month = datetime.fromtimestamp(before).strftime('%m')\n",
    "        print(f\"starting on month {datetime.fromtimestamp(before).strftime('%m')}.\")\n",
    "    \n",
    "    # append new_df to data\n",
    "    june_comments = june_comments.append(new_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9376fd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting on month 05.\n",
      "starting on month 04.\n"
     ]
    }
   ],
   "source": [
    "# get all posts from June on back to Jan 1 2021\n",
    "before = 1622523600\n",
    "may_comments = pd.DataFrame()\n",
    "newest_month = 0\n",
    "\n",
    "while before > 1619845200:\n",
    "    # make request\n",
    "    time.sleep(3)\n",
    "    res = requests.get(f\"https://api.pushshift.io/reddit/search/comment/?subreddit=gme&sort=desc&sort_type=created_utc&after=1609480800&before={before}&size=500\")\n",
    "    if res.ok == False and res.status_code >= 500:\n",
    "        continue\n",
    "    if res.ok == False and res.status_code < 500:\n",
    "        print(\"too many requests\")\n",
    "        break\n",
    "    # check for empty set\n",
    "    if res.text == '{\\n    \"data\": []\\n}':\n",
    "        continue\n",
    "    # get dataframe from response\n",
    "    new_df = df_from_comment(res)\n",
    "    # take the final row (oldest entry)\n",
    "    row = new_df.iloc[len(new_df)-1]\n",
    "    # get earliest date\n",
    "    before = int(row['utc_raw'])\n",
    "    # show where we're at\n",
    "    if datetime.fromtimestamp(before).strftime('%m') != newest_month:\n",
    "        newest_month = datetime.fromtimestamp(before).strftime('%m')\n",
    "        print(f\"starting on month {datetime.fromtimestamp(before).strftime('%m')}.\")\n",
    "    \n",
    "    # append new_df to data\n",
    "    may_comments = may_comments.append(new_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "491b7651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting on month 04.\n",
      "starting on month 03.\n"
     ]
    }
   ],
   "source": [
    "# get all posts from June on back to Jan 1 2021\n",
    "before = 1619845200\n",
    "apr_comments = pd.DataFrame()\n",
    "newest_month = 0\n",
    "\n",
    "while before > 1617253200:\n",
    "    # make request\n",
    "    time.sleep(3)\n",
    "    res = requests.get(f\"https://api.pushshift.io/reddit/search/comment/?subreddit=gme&sort=desc&sort_type=created_utc&after=1609480800&before={before}&size=500\")\n",
    "    if res.ok == False and res.status_code >= 500:\n",
    "        continue\n",
    "    if res.ok == False and res.status_code < 500:\n",
    "        print(\"too many requests\")\n",
    "        break\n",
    "    # check for empty set\n",
    "    if res.text == '{\\n    \"data\": []\\n}':\n",
    "        continue\n",
    "    # get dataframe from response\n",
    "    new_df = df_from_comment(res)\n",
    "    # take the final row (oldest entry)\n",
    "    row = new_df.iloc[len(new_df)-1]\n",
    "    # get earliest date\n",
    "    before = int(row['utc_raw'])\n",
    "    # show where we're at\n",
    "    if datetime.fromtimestamp(before).strftime('%m') != newest_month:\n",
    "        newest_month = datetime.fromtimestamp(before).strftime('%m')\n",
    "        print(f\"starting on month {datetime.fromtimestamp(before).strftime('%m')}.\")\n",
    "    \n",
    "    # append new_df to data\n",
    "    apr_comments = apr_comments.append(new_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f934638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting on month 03.\n",
      "10000 processed so far.\n",
      "20000 processed so far.\n",
      "30000 processed so far.\n",
      "40000 processed so far.\n",
      "50000 processed so far.\n",
      "60000 processed so far.\n",
      "70000 processed so far.\n",
      "80000 processed so far.\n",
      "90000 processed so far.\n",
      "100000 processed so far.\n",
      "110000 processed so far.\n",
      "120000 processed so far.\n",
      "130000 processed so far.\n",
      "140000 processed so far.\n",
      "150000 processed so far.\n",
      "160000 processed so far.\n",
      "170000 processed so far.\n",
      "180000 processed so far.\n",
      "190000 processed so far.\n",
      "200000 processed so far.\n",
      "210000 processed so far.\n",
      "220000 processed so far.\n",
      "230000 processed so far.\n",
      "240000 processed so far.\n",
      "250000 processed so far.\n",
      "260000 processed so far.\n",
      "270000 processed so far.\n",
      "280000 processed so far.\n",
      "290000 processed so far.\n",
      "300000 processed so far.\n",
      "310000 processed so far.\n",
      "320000 processed so far.\n",
      "330000 processed so far.\n",
      "340000 processed so far.\n",
      "350000 processed so far.\n",
      "360000 processed so far.\n",
      "370000 processed so far.\n",
      "380000 processed so far.\n",
      "390000 processed so far.\n",
      "400000 processed so far.\n",
      "410000 processed so far.\n",
      "420000 processed so far.\n",
      "430000 processed so far.\n",
      "440000 processed so far.\n",
      "450000 processed so far.\n",
      "460000 processed so far.\n",
      "470000 processed so far.\n",
      "480000 processed so far.\n",
      "490000 processed so far.\n",
      "500000 processed so far.\n",
      "510000 processed so far.\n",
      "520000 processed so far.\n",
      "530000 processed so far.\n",
      "540000 processed so far.\n",
      "550000 processed so far.\n",
      "560000 processed so far.\n",
      "570000 processed so far.\n",
      "580000 processed so far.\n",
      "590000 processed so far.\n",
      "600000 processed so far.\n",
      "610000 processed so far.\n",
      "620000 processed so far.\n",
      "630000 processed so far.\n",
      "640000 processed so far.\n",
      "650000 processed so far.\n",
      "660000 processed so far.\n",
      "670000 processed so far.\n",
      "680000 processed so far.\n",
      "690000 processed so far.\n",
      "700000 processed so far.\n",
      "710000 processed so far.\n",
      "720000 processed so far.\n",
      "730000 processed so far.\n",
      "740000 processed so far.\n",
      "750000 processed so far.\n",
      "760000 processed so far.\n",
      "770000 processed so far.\n",
      "780000 processed so far.\n",
      "790000 processed so far.\n",
      "800000 processed so far.\n",
      "810000 processed so far.\n",
      "820000 processed so far.\n",
      "830000 processed so far.\n",
      "840000 processed so far.\n",
      "850000 processed so far.\n",
      "860000 processed so far.\n",
      "870000 processed so far.\n",
      "880000 processed so far.\n",
      "890000 processed so far.\n",
      "900000 processed so far.\n",
      "910000 processed so far.\n",
      "920000 processed so far.\n",
      "930000 processed so far.\n",
      "940000 processed so far.\n",
      "950000 processed so far.\n",
      "960000 processed so far.\n",
      "970000 processed so far.\n",
      "980000 processed so far.\n",
      "990000 processed so far.\n",
      "1000000 processed so far.\n",
      "1010000 processed so far.\n",
      "1020000 processed so far.\n",
      "1030000 processed so far.\n",
      "1040000 processed so far.\n",
      "1050000 processed so far.\n",
      "1060000 processed so far.\n",
      "1070000 processed so far.\n",
      "1080000 processed so far.\n",
      "1090000 processed so far.\n",
      "1100000 processed so far.\n",
      "1110000 processed so far.\n",
      "1120000 processed so far.\n",
      "1130000 processed so far.\n",
      "1140000 processed so far.\n",
      "1150000 processed so far.\n",
      "1160000 processed so far.\n",
      "1170000 processed so far.\n",
      "1180000 processed so far.\n",
      "1190000 processed so far.\n",
      "1200000 processed so far.\n",
      "1210000 processed so far.\n",
      "1220000 processed so far.\n",
      "1230000 processed so far.\n",
      "1240000 processed so far.\n",
      "1250000 processed so far.\n",
      "1260000 processed so far.\n",
      "1270000 processed so far.\n",
      "1280000 processed so far.\n",
      "1290000 processed so far.\n",
      "1300000 processed so far.\n",
      "1310000 processed so far.\n",
      "1320000 processed so far.\n",
      "1330000 processed so far.\n",
      "1340000 processed so far.\n",
      "1350000 processed so far.\n",
      "1360000 processed so far.\n",
      "1370000 processed so far.\n",
      "1380000 processed so far.\n",
      "1390000 processed so far.\n",
      "1400000 processed so far.\n",
      "1410000 processed so far.\n",
      "1420000 processed so far.\n",
      "1430000 processed so far.\n",
      "1440000 processed so far.\n",
      "1450000 processed so far.\n",
      "1460000 processed so far.\n",
      "1470000 processed so far.\n",
      "1480000 processed so far.\n",
      "1490000 processed so far.\n",
      "1500000 processed so far.\n",
      "1510000 processed so far.\n",
      "1520000 processed so far.\n",
      "1530000 processed so far.\n",
      "1540000 processed so far.\n",
      "1550000 processed so far.\n",
      "1560000 processed so far.\n",
      "1570000 processed so far.\n",
      "1580000 processed so far.\n",
      "1590000 processed so far.\n",
      "1600000 processed so far.\n",
      "1610000 processed so far.\n",
      "1620000 processed so far.\n",
      "1630000 processed so far.\n",
      "1640000 processed so far.\n",
      "1650000 processed so far.\n",
      "1660000 processed so far.\n",
      "1670000 processed so far.\n",
      "1680000 processed so far.\n",
      "1690000 processed so far.\n",
      "1700000 processed so far.\n",
      "1710000 processed so far.\n",
      "1720000 processed so far.\n",
      "1730000 processed so far.\n",
      "1740000 processed so far.\n",
      "1750000 processed so far.\n",
      "1760000 processed so far.\n",
      "1770000 processed so far.\n",
      "1780000 processed so far.\n",
      "1790000 processed so far.\n",
      "1800000 processed so far.\n",
      "1810000 processed so far.\n",
      "1820000 processed so far.\n",
      "1830000 processed so far.\n",
      "1840000 processed so far.\n",
      "1850000 processed so far.\n",
      "1860000 processed so far.\n",
      "1870000 processed so far.\n",
      "1880000 processed so far.\n",
      "1890000 processed so far.\n",
      "1900000 processed so far.\n",
      "1910000 processed so far.\n",
      "1920000 processed so far.\n",
      "1930000 processed so far.\n",
      "1940000 processed so far.\n",
      "1950000 processed so far.\n",
      "1960000 processed so far.\n",
      "1970000 processed so far.\n",
      "1980000 processed so far.\n",
      "1990000 processed so far.\n",
      "2000000 processed so far.\n",
      "2010000 processed so far.\n",
      "2020000 processed so far.\n",
      "2030000 processed so far.\n",
      "2040000 processed so far.\n",
      "2050000 processed so far.\n",
      "2060000 processed so far.\n",
      "2070000 processed so far.\n",
      "2080000 processed so far.\n",
      "2090000 processed so far.\n",
      "2100000 processed so far.\n",
      "2110000 processed so far.\n",
      "2120000 processed so far.\n",
      "2130000 processed so far.\n",
      "2140000 processed so far.\n",
      "2150000 processed so far.\n",
      "2160000 processed so far.\n",
      "2170000 processed so far.\n",
      "2180000 processed so far.\n",
      "2190000 processed so far.\n",
      "2200000 processed so far.\n",
      "2210000 processed so far.\n",
      "2220000 processed so far.\n",
      "2230000 processed so far.\n",
      "2240000 processed so far.\n",
      "2250000 processed so far.\n",
      "2260000 processed so far.\n",
      "2270000 processed so far.\n",
      "2280000 processed so far.\n",
      "2290000 processed so far.\n",
      "2300000 processed so far.\n",
      "2310000 processed so far.\n",
      "2320000 processed so far.\n",
      "2330000 processed so far.\n",
      "2340000 processed so far.\n",
      "2350000 processed so far.\n",
      "2360000 processed so far.\n",
      "2370000 processed so far.\n",
      "2380000 processed so far.\n",
      "2390000 processed so far.\n",
      "2400000 processed so far.\n",
      "2410000 processed so far.\n",
      "2420000 processed so far.\n",
      "2430000 processed so far.\n",
      "2440000 processed so far.\n",
      "2450000 processed so far.\n",
      "2460000 processed so far.\n",
      "2470000 processed so far.\n",
      "2480000 processed so far.\n",
      "2490000 processed so far.\n",
      "2500000 processed so far.\n",
      "2510000 processed so far.\n",
      "2520000 processed so far.\n",
      "2530000 processed so far.\n",
      "2540000 processed so far.\n",
      "2550000 processed so far.\n",
      "2560000 processed so far.\n",
      "2570000 processed so far.\n",
      "2580000 processed so far.\n",
      "2590000 processed so far.\n",
      "2600000 processed so far.\n",
      "2610000 processed so far.\n",
      "2620000 processed so far.\n",
      "2630000 processed so far.\n",
      "2640000 processed so far.\n",
      "2650000 processed so far.\n",
      "2660000 processed so far.\n",
      "2670000 processed so far.\n",
      "2680000 processed so far.\n",
      "2690000 processed so far.\n",
      "2700000 processed so far.\n",
      "2710000 processed so far.\n",
      "2720000 processed so far.\n",
      "2730000 processed so far.\n",
      "2740000 processed so far.\n",
      "2750000 processed so far.\n",
      "2760000 processed so far.\n",
      "2770000 processed so far.\n",
      "2780000 processed so far.\n",
      "2790000 processed so far.\n",
      "2800000 processed so far.\n",
      "2810000 processed so far.\n",
      "2820000 processed so far.\n",
      "2830000 processed so far.\n",
      "2840000 processed so far.\n",
      "2850000 processed so far.\n",
      "2860000 processed so far.\n",
      "2870000 processed so far.\n",
      "2880000 processed so far.\n",
      "2890000 processed so far.\n",
      "2900000 processed so far.\n",
      "2910000 processed so far.\n",
      "2920000 processed so far.\n",
      "2930000 processed so far.\n",
      "2940000 processed so far.\n",
      "2950000 processed so far.\n",
      "2960000 processed so far.\n",
      "2970000 processed so far.\n",
      "2980000 processed so far.\n",
      "2990000 processed so far.\n",
      "3000000 processed so far.\n",
      "3010000 processed so far.\n",
      "3020000 processed so far.\n",
      "3030000 processed so far.\n",
      "3040000 processed so far.\n",
      "3050000 processed so far.\n",
      "3060000 processed so far.\n",
      "3070000 processed so far.\n",
      "3080000 processed so far.\n",
      "3090000 processed so far.\n",
      "3100000 processed so far.\n",
      "3110000 processed so far.\n",
      "3120000 processed so far.\n",
      "3130000 processed so far.\n",
      "3140000 processed so far.\n",
      "3150000 processed so far.\n",
      "3160000 processed so far.\n",
      "3170000 processed so far.\n",
      "3180000 processed so far.\n",
      "3190000 processed so far.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200000 processed so far.\n",
      "3210000 processed so far.\n",
      "3220000 processed so far.\n",
      "3230000 processed so far.\n",
      "3240000 processed so far.\n",
      "3250000 processed so far.\n",
      "3260000 processed so far.\n",
      "3270000 processed so far.\n",
      "3280000 processed so far.\n",
      "3290000 processed so far.\n",
      "3300000 processed so far.\n",
      "3310000 processed so far.\n",
      "3320000 processed so far.\n",
      "3330000 processed so far.\n",
      "3340000 processed so far.\n",
      "3350000 processed so far.\n",
      "3360000 processed so far.\n",
      "3370000 processed so far.\n",
      "3380000 processed so far.\n",
      "3390000 processed so far.\n",
      "3400000 processed so far.\n",
      "3410000 processed so far.\n",
      "3420000 processed so far.\n",
      "3430000 processed so far.\n",
      "3440000 processed so far.\n",
      "3450000 processed so far.\n",
      "3460000 processed so far.\n",
      "3470000 processed so far.\n",
      "3480000 processed so far.\n",
      "3490000 processed so far.\n",
      "3500000 processed so far.\n",
      "3510000 processed so far.\n",
      "3520000 processed so far.\n",
      "3530000 processed so far.\n",
      "3540000 processed so far.\n",
      "3550000 processed so far.\n",
      "3560000 processed so far.\n",
      "3570000 processed so far.\n",
      "3580000 processed so far.\n",
      "3590000 processed so far.\n",
      "3600000 processed so far.\n",
      "3610000 processed so far.\n",
      "3620000 processed so far.\n",
      "3630000 processed so far.\n",
      "3640000 processed so far.\n",
      "3650000 processed so far.\n",
      "3660000 processed so far.\n",
      "3670000 processed so far.\n",
      "3680000 processed so far.\n",
      "3690000 processed so far.\n",
      "3700000 processed so far.\n",
      "3710000 processed so far.\n",
      "3720000 processed so far.\n",
      "3730000 processed so far.\n",
      "3740000 processed so far.\n",
      "3750000 processed so far.\n",
      "3760000 processed so far.\n",
      "3770000 processed so far.\n",
      "3780000 processed so far.\n",
      "3790000 processed so far.\n",
      "3800000 processed so far.\n",
      "3810000 processed so far.\n",
      "3820000 processed so far.\n",
      "3830000 processed so far.\n",
      "3840000 processed so far.\n",
      "3850000 processed so far.\n",
      "3860000 processed so far.\n",
      "3870000 processed so far.\n",
      "3880000 processed so far.\n",
      "3890000 processed so far.\n",
      "3900000 processed so far.\n",
      "3910000 processed so far.\n",
      "3920000 processed so far.\n",
      "3930000 processed so far.\n",
      "3940000 processed so far.\n",
      "3950000 processed so far.\n",
      "3960000 processed so far.\n",
      "3970000 processed so far.\n",
      "3980000 processed so far.\n",
      "3990000 processed so far.\n",
      "4000000 processed so far.\n",
      "4010000 processed so far.\n",
      "4020000 processed so far.\n",
      "4030000 processed so far.\n",
      "4040000 processed so far.\n",
      "4050000 processed so far.\n",
      "4060000 processed so far.\n",
      "4070000 processed so far.\n",
      "4080000 processed so far.\n",
      "4090000 processed so far.\n",
      "4100000 processed so far.\n",
      "4110000 processed so far.\n",
      "4120000 processed so far.\n",
      "4130000 processed so far.\n",
      "4140000 processed so far.\n",
      "4150000 processed so far.\n",
      "4160000 processed so far.\n",
      "4170000 processed so far.\n",
      "4180000 processed so far.\n",
      "4190000 processed so far.\n",
      "4200000 processed so far.\n",
      "4210000 processed so far.\n",
      "4220000 processed so far.\n",
      "4230000 processed so far.\n",
      "4240000 processed so far.\n",
      "4250000 processed so far.\n",
      "4260000 processed so far.\n",
      "4270000 processed so far.\n",
      "4280000 processed so far.\n",
      "4290000 processed so far.\n",
      "4300000 processed so far.\n",
      "4310000 processed so far.\n",
      "4320000 processed so far.\n",
      "4330000 processed so far.\n",
      "4340000 processed so far.\n",
      "4350000 processed so far.\n",
      "4360000 processed so far.\n",
      "4370000 processed so far.\n",
      "4380000 processed so far.\n",
      "4390000 processed so far.\n",
      "4400000 processed so far.\n",
      "4410000 processed so far.\n",
      "4420000 processed so far.\n",
      "4430000 processed so far.\n",
      "4440000 processed so far.\n",
      "4450000 processed so far.\n",
      "4460000 processed so far.\n",
      "4470000 processed so far.\n",
      "4480000 processed so far.\n",
      "4490000 processed so far.\n",
      "4500000 processed so far.\n",
      "4510000 processed so far.\n",
      "4520000 processed so far.\n",
      "4530000 processed so far.\n",
      "4540000 processed so far.\n",
      "4550000 processed so far.\n",
      "4560000 processed so far.\n",
      "4570000 processed so far.\n",
      "4580000 processed so far.\n",
      "4590000 processed so far.\n",
      "4600000 processed so far.\n",
      "4610000 processed so far.\n",
      "4620000 processed so far.\n",
      "4630000 processed so far.\n",
      "4640000 processed so far.\n",
      "4650000 processed so far.\n",
      "4660000 processed so far.\n",
      "4670000 processed so far.\n",
      "4680000 processed so far.\n",
      "4690000 processed so far.\n",
      "4700000 processed so far.\n",
      "4710000 processed so far.\n",
      "4720000 processed so far.\n",
      "4730000 processed so far.\n",
      "4740000 processed so far.\n",
      "4750000 processed so far.\n",
      "4760000 processed so far.\n",
      "4770000 processed so far.\n",
      "4780000 processed so far.\n",
      "4790000 processed so far.\n",
      "4800000 processed so far.\n",
      "4810000 processed so far.\n",
      "4820000 processed so far.\n",
      "4830000 processed so far.\n",
      "4840000 processed so far.\n",
      "4850000 processed so far.\n",
      "4860000 processed so far.\n",
      "4870000 processed so far.\n",
      "4880000 processed so far.\n",
      "4890000 processed so far.\n",
      "4900000 processed so far.\n",
      "4910000 processed so far.\n",
      "4920000 processed so far.\n",
      "4930000 processed so far.\n",
      "4940000 processed so far.\n",
      "4950000 processed so far.\n",
      "4960000 processed so far.\n",
      "4970000 processed so far.\n",
      "4980000 processed so far.\n",
      "4990000 processed so far.\n",
      "5000000 processed so far.\n",
      "5010000 processed so far.\n",
      "5020000 processed so far.\n",
      "5030000 processed so far.\n",
      "5040000 processed so far.\n",
      "5050000 processed so far.\n",
      "5060000 processed so far.\n",
      "5070000 processed so far.\n",
      "5080000 processed so far.\n",
      "5090000 processed so far.\n",
      "5100000 processed so far.\n",
      "5110000 processed so far.\n",
      "5120000 processed so far.\n",
      "5130000 processed so far.\n",
      "5140000 processed so far.\n",
      "5150000 processed so far.\n",
      "5160000 processed so far.\n",
      "5170000 processed so far.\n",
      "5180000 processed so far.\n",
      "5190000 processed so far.\n",
      "5200000 processed so far.\n",
      "5210000 processed so far.\n",
      "5220000 processed so far.\n",
      "5230000 processed so far.\n",
      "5240000 processed so far.\n",
      "5250000 processed so far.\n",
      "5260000 processed so far.\n",
      "5270000 processed so far.\n",
      "5280000 processed so far.\n",
      "5290000 processed so far.\n",
      "5300000 processed so far.\n",
      "5310000 processed so far.\n",
      "5320000 processed so far.\n",
      "5330000 processed so far.\n",
      "5340000 processed so far.\n",
      "5350000 processed so far.\n",
      "5360000 processed so far.\n",
      "5370000 processed so far.\n",
      "5380000 processed so far.\n",
      "5390000 processed so far.\n",
      "5400000 processed so far.\n",
      "5410000 processed so far.\n",
      "5420000 processed so far.\n",
      "5430000 processed so far.\n",
      "5440000 processed so far.\n",
      "5450000 processed so far.\n",
      "5460000 processed so far.\n",
      "5470000 processed so far.\n",
      "5480000 processed so far.\n",
      "5490000 processed so far.\n",
      "5500000 processed so far.\n",
      "5510000 processed so far.\n",
      "5520000 processed so far.\n",
      "5530000 processed so far.\n",
      "5540000 processed so far.\n",
      "5550000 processed so far.\n",
      "5560000 processed so far.\n",
      "5570000 processed so far.\n",
      "5580000 processed so far.\n",
      "5590000 processed so far.\n",
      "5600000 processed so far.\n",
      "5610000 processed so far.\n",
      "5620000 processed so far.\n",
      "5630000 processed so far.\n",
      "5640000 processed so far.\n",
      "5650000 processed so far.\n",
      "5660000 processed so far.\n",
      "5670000 processed so far.\n",
      "5680000 processed so far.\n",
      "5690000 processed so far.\n",
      "5700000 processed so far.\n",
      "5710000 processed so far.\n",
      "5720000 processed so far.\n",
      "5730000 processed so far.\n",
      "5740000 processed so far.\n",
      "5750000 processed so far.\n",
      "5760000 processed so far.\n",
      "5770000 processed so far.\n",
      "5780000 processed so far.\n",
      "5790000 processed so far.\n",
      "5800000 processed so far.\n",
      "5810000 processed so far.\n",
      "5820000 processed so far.\n",
      "5830000 processed so far.\n",
      "5840000 processed so far.\n",
      "5850000 processed so far.\n",
      "starting on month 02.\n"
     ]
    }
   ],
   "source": [
    "# get all posts from June on back to Jan 1 2021\n",
    "before = 1617253200\n",
    "mar_comments = pd.DataFrame()\n",
    "newest_month = 0\n",
    "tot_comments = 0\n",
    "while before > 1614578400:\n",
    "    # make request\n",
    "    time.sleep(3)\n",
    "    res = requests.get(f\"https://api.pushshift.io/reddit/search/comment/?subreddit=gme&sort=desc&sort_type=created_utc&after=1609480800&before={before}&size=500\")\n",
    "    if res.ok == False and res.status_code >= 500:\n",
    "        continue\n",
    "    if res.ok == False and res.status_code < 500:\n",
    "        print(\"too many requests\")\n",
    "        break\n",
    "    # check for empty set\n",
    "    if res.text == '{\\n    \"data\": []\\n}':\n",
    "        continue\n",
    "    # get dataframe from response\n",
    "    new_df = df_from_comment(res)\n",
    "    # take the final row (oldest entry)\n",
    "    row = new_df.iloc[len(new_df)-1]\n",
    "    # get earliest date\n",
    "    before = int(row['utc_raw'])\n",
    "    # show where we're at\n",
    "    if datetime.fromtimestamp(before).strftime('%m') != newest_month:\n",
    "        newest_month = datetime.fromtimestamp(before).strftime('%m')\n",
    "        print(f\"starting on month {datetime.fromtimestamp(before).strftime('%m')}.\")\n",
    "    tot_comments += 500\n",
    "    if tot_comments % 10000 == 0 and tot_comments > 0:\n",
    "            print(f'{tot_comments} processed so far.')\n",
    "     \n",
    "    # append new_df to data\n",
    "    mar_comments = mar_comments.append(new_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec04f7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting on month 02.\n",
      "10000 processed so far.\n",
      "20000 processed so far.\n",
      "30000 processed so far.\n",
      "40000 processed so far.\n",
      "50000 processed so far.\n",
      "60000 processed so far.\n",
      "70000 processed so far.\n",
      "80000 processed so far.\n",
      "90000 processed so far.\n",
      "100000 processed so far.\n",
      "110000 processed so far.\n",
      "120000 processed so far.\n",
      "130000 processed so far.\n",
      "140000 processed so far.\n",
      "150000 processed so far.\n",
      "160000 processed so far.\n",
      "170000 processed so far.\n",
      "180000 processed so far.\n",
      "190000 processed so far.\n",
      "200000 processed so far.\n",
      "210000 processed so far.\n",
      "220000 processed so far.\n",
      "230000 processed so far.\n",
      "240000 processed so far.\n",
      "250000 processed so far.\n",
      "260000 processed so far.\n",
      "270000 processed so far.\n",
      "280000 processed so far.\n",
      "290000 processed so far.\n",
      "300000 processed so far.\n",
      "310000 processed so far.\n",
      "320000 processed so far.\n",
      "330000 processed so far.\n",
      "340000 processed so far.\n",
      "350000 processed so far.\n",
      "360000 processed so far.\n",
      "370000 processed so far.\n",
      "380000 processed so far.\n",
      "390000 processed so far.\n",
      "400000 processed so far.\n",
      "410000 processed so far.\n",
      "420000 processed so far.\n",
      "430000 processed so far.\n",
      "440000 processed so far.\n",
      "450000 processed so far.\n",
      "460000 processed so far.\n",
      "470000 processed so far.\n",
      "480000 processed so far.\n",
      "490000 processed so far.\n",
      "500000 processed so far.\n",
      "510000 processed so far.\n",
      "520000 processed so far.\n",
      "530000 processed so far.\n",
      "540000 processed so far.\n",
      "550000 processed so far.\n",
      "560000 processed so far.\n",
      "570000 processed so far.\n",
      "580000 processed so far.\n",
      "590000 processed so far.\n",
      "600000 processed so far.\n",
      "610000 processed so far.\n",
      "620000 processed so far.\n",
      "630000 processed so far.\n",
      "640000 processed so far.\n",
      "650000 processed so far.\n",
      "660000 processed so far.\n",
      "670000 processed so far.\n",
      "680000 processed so far.\n",
      "690000 processed so far.\n",
      "700000 processed so far.\n",
      "710000 processed so far.\n",
      "720000 processed so far.\n",
      "730000 processed so far.\n",
      "740000 processed so far.\n",
      "750000 processed so far.\n",
      "760000 processed so far.\n",
      "770000 processed so far.\n",
      "780000 processed so far.\n",
      "790000 processed so far.\n",
      "800000 processed so far.\n",
      "810000 processed so far.\n",
      "820000 processed so far.\n",
      "830000 processed so far.\n",
      "840000 processed so far.\n",
      "850000 processed so far.\n",
      "860000 processed so far.\n",
      "870000 processed so far.\n",
      "880000 processed so far.\n",
      "890000 processed so far.\n",
      "900000 processed so far.\n",
      "910000 processed so far.\n",
      "920000 processed so far.\n",
      "930000 processed so far.\n",
      "940000 processed so far.\n",
      "950000 processed so far.\n",
      "960000 processed so far.\n",
      "970000 processed so far.\n",
      "980000 processed so far.\n",
      "990000 processed so far.\n",
      "1000000 processed so far.\n",
      "1010000 processed so far.\n",
      "1020000 processed so far.\n",
      "1030000 processed so far.\n",
      "1040000 processed so far.\n",
      "1050000 processed so far.\n",
      "1060000 processed so far.\n",
      "1070000 processed so far.\n",
      "1080000 processed so far.\n",
      "1090000 processed so far.\n",
      "1100000 processed so far.\n",
      "1110000 processed so far.\n",
      "1120000 processed so far.\n",
      "1130000 processed so far.\n",
      "1140000 processed so far.\n",
      "1150000 processed so far.\n",
      "1160000 processed so far.\n",
      "1170000 processed so far.\n",
      "1180000 processed so far.\n",
      "1190000 processed so far.\n",
      "1200000 processed so far.\n",
      "1210000 processed so far.\n",
      "1220000 processed so far.\n",
      "1230000 processed so far.\n",
      "1240000 processed so far.\n",
      "1250000 processed so far.\n",
      "1260000 processed so far.\n",
      "1270000 processed so far.\n",
      "1280000 processed so far.\n",
      "1290000 processed so far.\n",
      "1300000 processed so far.\n",
      "1310000 processed so far.\n",
      "1320000 processed so far.\n",
      "1330000 processed so far.\n",
      "1340000 processed so far.\n",
      "1350000 processed so far.\n",
      "1360000 processed so far.\n",
      "1370000 processed so far.\n",
      "1380000 processed so far.\n",
      "1390000 processed so far.\n",
      "1400000 processed so far.\n",
      "1410000 processed so far.\n",
      "1420000 processed so far.\n",
      "1430000 processed so far.\n",
      "1440000 processed so far.\n",
      "1450000 processed so far.\n",
      "1460000 processed so far.\n",
      "1470000 processed so far.\n",
      "1480000 processed so far.\n",
      "1490000 processed so far.\n",
      "1500000 processed so far.\n",
      "1510000 processed so far.\n",
      "1520000 processed so far.\n",
      "1530000 processed so far.\n",
      "1540000 processed so far.\n",
      "1550000 processed so far.\n",
      "1560000 processed so far.\n",
      "1570000 processed so far.\n",
      "1580000 processed so far.\n",
      "1590000 processed so far.\n",
      "1600000 processed so far.\n",
      "1610000 processed so far.\n",
      "1620000 processed so far.\n",
      "1630000 processed so far.\n",
      "1640000 processed so far.\n",
      "1650000 processed so far.\n",
      "1660000 processed so far.\n",
      "1670000 processed so far.\n",
      "1680000 processed so far.\n",
      "1690000 processed so far.\n",
      "1700000 processed so far.\n",
      "1710000 processed so far.\n",
      "1720000 processed so far.\n",
      "1730000 processed so far.\n",
      "1740000 processed so far.\n",
      "1750000 processed so far.\n",
      "1760000 processed so far.\n",
      "1770000 processed so far.\n",
      "1780000 processed so far.\n",
      "1790000 processed so far.\n",
      "1800000 processed so far.\n",
      "1810000 processed so far.\n",
      "1820000 processed so far.\n",
      "1830000 processed so far.\n",
      "1840000 processed so far.\n",
      "1850000 processed so far.\n",
      "1860000 processed so far.\n",
      "1870000 processed so far.\n",
      "1880000 processed so far.\n",
      "1890000 processed so far.\n",
      "1900000 processed so far.\n",
      "1910000 processed so far.\n",
      "1920000 processed so far.\n",
      "1930000 processed so far.\n",
      "1940000 processed so far.\n",
      "1950000 processed so far.\n",
      "1960000 processed so far.\n",
      "1970000 processed so far.\n",
      "1980000 processed so far.\n",
      "1990000 processed so far.\n",
      "2000000 processed so far.\n",
      "2010000 processed so far.\n",
      "2020000 processed so far.\n",
      "2030000 processed so far.\n",
      "2040000 processed so far.\n",
      "2050000 processed so far.\n",
      "2060000 processed so far.\n",
      "2070000 processed so far.\n",
      "2080000 processed so far.\n",
      "2090000 processed so far.\n",
      "2100000 processed so far.\n",
      "2110000 processed so far.\n",
      "2120000 processed so far.\n",
      "2130000 processed so far.\n",
      "2140000 processed so far.\n",
      "2150000 processed so far.\n",
      "2160000 processed so far.\n",
      "2170000 processed so far.\n",
      "2180000 processed so far.\n",
      "2190000 processed so far.\n",
      "2200000 processed so far.\n",
      "2210000 processed so far.\n",
      "2220000 processed so far.\n",
      "2230000 processed so far.\n",
      "2240000 processed so far.\n",
      "2250000 processed so far.\n",
      "2260000 processed so far.\n",
      "2270000 processed so far.\n",
      "2280000 processed so far.\n",
      "2290000 processed so far.\n",
      "2300000 processed so far.\n",
      "2310000 processed so far.\n",
      "2320000 processed so far.\n",
      "2330000 processed so far.\n",
      "2340000 processed so far.\n",
      "2350000 processed so far.\n",
      "2360000 processed so far.\n",
      "2370000 processed so far.\n",
      "2380000 processed so far.\n",
      "2390000 processed so far.\n",
      "2400000 processed so far.\n",
      "2410000 processed so far.\n",
      "2420000 processed so far.\n",
      "2430000 processed so far.\n",
      "2440000 processed so far.\n",
      "2450000 processed so far.\n",
      "2460000 processed so far.\n",
      "2470000 processed so far.\n",
      "2480000 processed so far.\n",
      "2490000 processed so far.\n",
      "2500000 processed so far.\n",
      "2510000 processed so far.\n",
      "2520000 processed so far.\n",
      "2530000 processed so far.\n",
      "2540000 processed so far.\n",
      "2550000 processed so far.\n",
      "2560000 processed so far.\n",
      "2570000 processed so far.\n",
      "2580000 processed so far.\n",
      "2590000 processed so far.\n",
      "starting on month 01.\n"
     ]
    }
   ],
   "source": [
    "# get all posts from June on back to Jan 1 2021\n",
    "before = 1614578400\n",
    "feb_comments = pd.DataFrame()\n",
    "newest_month = 0\n",
    "tot_comments = 0\n",
    "while before > 1612159200:\n",
    "    # make request\n",
    "    time.sleep(3)\n",
    "    res = requests.get(f\"https://api.pushshift.io/reddit/search/comment/?subreddit=gme&sort=desc&sort_type=created_utc&after=1609480800&before={before}&size=500\")\n",
    "    if res.ok == False and res.status_code >= 500:\n",
    "        continue\n",
    "    if res.ok == False and res.status_code < 500:\n",
    "        print(\"too many requests\")\n",
    "        break\n",
    "    # check for empty set\n",
    "    if res.text == '{\\n    \"data\": []\\n}':\n",
    "        continue\n",
    "    # get dataframe from response\n",
    "    new_df = df_from_comment(res)\n",
    "    # take the final row (oldest entry)\n",
    "    row = new_df.iloc[len(new_df)-1]\n",
    "    # get earliest date\n",
    "    before = int(row['utc_raw'])\n",
    "    # show where we're at\n",
    "    if datetime.fromtimestamp(before).strftime('%m') != newest_month:\n",
    "        newest_month = datetime.fromtimestamp(before).strftime('%m')\n",
    "        print(f\"starting on month {datetime.fromtimestamp(before).strftime('%m')}.\")\n",
    "    tot_comments += 500\n",
    "    if tot_comments % 10000 == 0 and tot_comments > 0:\n",
    "            print(f'{tot_comments} processed so far.')\n",
    "     \n",
    "    # append new_df to data\n",
    "    feb_comments = feb_comments.append(new_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20bd6b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting on month 01.\n",
      "10000 processed so far.\n",
      "20000 processed so far.\n",
      "30000 processed so far.\n",
      "40000 processed so far.\n",
      "50000 processed so far.\n",
      "60000 processed so far.\n",
      "70000 processed so far.\n",
      "80000 processed so far.\n",
      "90000 processed so far.\n",
      "100000 processed so far.\n",
      "110000 processed so far.\n",
      "120000 processed so far.\n",
      "130000 processed so far.\n",
      "140000 processed so far.\n"
     ]
    }
   ],
   "source": [
    "# get all posts from June on back to Jan 1 2021\n",
    "before = 1612159200\n",
    "jan_comments = pd.DataFrame()\n",
    "newest_month = 0\n",
    "tot_comments = 0\n",
    "while before > 1609480800:\n",
    "    # make request\n",
    "    time.sleep(3)\n",
    "    res = requests.get(f\"https://api.pushshift.io/reddit/search/comment/?subreddit=gme&sort=desc&sort_type=created_utc&after=1609480800&before={before}&size=500\")\n",
    "    if res.ok == False and res.status_code >= 500:\n",
    "        continue\n",
    "    if res.ok == False and res.status_code < 500:\n",
    "        print(\"too many requests\")\n",
    "        break\n",
    "    # check for empty set\n",
    "    if res.text == '{\\n    \"data\": []\\n}':\n",
    "        break\n",
    "    # get dataframe from response\n",
    "    new_df = df_from_comment(res)\n",
    "    # take the final row (oldest entry)\n",
    "    row = new_df.iloc[len(new_df)-1]\n",
    "    # get earliest date\n",
    "    before = int(row['utc_raw'])\n",
    "    # show where we're at\n",
    "    if datetime.fromtimestamp(before).strftime('%m') != newest_month:\n",
    "        newest_month = datetime.fromtimestamp(before).strftime('%m')\n",
    "        print(f\"starting on month {datetime.fromtimestamp(before).strftime('%m')}.\")\n",
    "    tot_comments += 500\n",
    "    if tot_comments % 10000 == 0 and tot_comments > 0:\n",
    "            print(f'{tot_comments} processed so far.')\n",
    "     \n",
    "    # append new_df to data\n",
    "    jan_comments = jan_comments.append(new_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d5f715f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28705\n"
     ]
    }
   ],
   "source": [
    "#print(len(apr_comments))\n",
    "# print(len(mar_comments))\n",
    "# print(len(feb_comments))\n",
    "print(len(jan_comments))\n",
    "\n",
    "#june_comments.to_csv(r\"C:\\Users\\Daniel\\Documents\\NLP Class\\Project\\gme_comments_jun.csv\")\n",
    "#may_comments.to_csv(r\"C:\\Users\\Daniel\\Documents\\NLP Class\\Project\\gme_comments_may.csv\")\n",
    "#apr_comments.to_csv(r\"C:\\Users\\Daniel\\Documents\\NLP Class\\Project\\gme_comments_apr.csv\")\n",
    "# mar_comments.to_csv(r\"C:\\Users\\Daniel\\Documents\\NLP Class\\Project\\gme_comments_mar.csv\")\n",
    "# feb_comments.to_csv(r\"C:\\Users\\Daniel\\Documents\\NLP Class\\Project\\gme_comments_feb.csv\")\n",
    "jan_comments.to_csv(r\"C:\\Users\\Daniel\\Documents\\NLP Class\\Project\\gme_comments_jan.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "769af53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>kind</th>\n",
       "      <th>parent</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>utc_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saluti dall'Italia, fanculo SEC!</td>\n",
       "      <td>2021-02-26T23:08:57Z</td>\n",
       "      <td>goy55dc</td>\n",
       "      <td>t2</td>\n",
       "      <td>t1_govbwlx</td>\n",
       "      <td>GME</td>\n",
       "      <td>1.614403e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>At this rate, by Paddy's Day the stock will ha...</td>\n",
       "      <td>2021-02-26T23:08:55Z</td>\n",
       "      <td>goy5549</td>\n",
       "      <td>t2</td>\n",
       "      <td>t1_gox1aj7</td>\n",
       "      <td>GME</td>\n",
       "      <td>1.614403e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>With the area code included! </td>\n",
       "      <td>2021-02-26T23:08:53Z</td>\n",
       "      <td>goy54vr</td>\n",
       "      <td>t2</td>\n",
       "      <td>t1_gowvasm</td>\n",
       "      <td>GME</td>\n",
       "      <td>1.614403e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Am retarded.   Am hodl.</td>\n",
       "      <td>2021-02-26T23:08:39Z</td>\n",
       "      <td>goy53g1</td>\n",
       "      <td>t2</td>\n",
       "      <td>t3_lt9x3l</td>\n",
       "      <td>GME</td>\n",
       "      <td>1.614403e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I like to keep things simple:\\n\\n see stock. ...</td>\n",
       "      <td>2021-02-26T23:08:36Z</td>\n",
       "      <td>goy532o</td>\n",
       "      <td>t2</td>\n",
       "      <td>t3_lt6zku</td>\n",
       "      <td>GME</td>\n",
       "      <td>1.614403e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body           created_utc  \\\n",
       "0                   Saluti dall'Italia, fanculo SEC!  2021-02-26T23:08:57Z   \n",
       "1  At this rate, by Paddy's Day the stock will ha...  2021-02-26T23:08:55Z   \n",
       "2                    With the area code included!   2021-02-26T23:08:53Z   \n",
       "3                            Am retarded.   Am hodl.  2021-02-26T23:08:39Z   \n",
       "4  I like to keep things simple:\\n\\n see stock. ...  2021-02-26T23:08:36Z   \n",
       "\n",
       "        id kind      parent subreddit       utc_raw  \n",
       "0  goy55dc   t2  t1_govbwlx       GME  1.614403e+09  \n",
       "1  goy5549   t2  t1_gox1aj7       GME  1.614403e+09  \n",
       "2  goy54vr   t2  t1_gowvasm       GME  1.614403e+09  \n",
       "3  goy53g1   t2   t3_lt9x3l       GME  1.614403e+09  \n",
       "4  goy532o   t2   t3_lt6zku       GME  1.614403e+09  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feb_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38f30ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(\"https://api.polygon.io/v1/open-close/GME/2020-10-14?adjusted=true&apiKey=FkJ0c2CuFs7HDQoJTSBaPXJdh_Mc90tU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bea027f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 0    2021-01-04\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-01-05\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-01-06\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-01-07\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-01-08\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-01-11\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-01-12\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-01-13\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-01-14\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-01-15\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-01-19\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-01-20\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-01-21\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-01-22\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-01-25\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-01-26\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-01-27\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-01-28\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-01-29\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-02-01\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-02-02\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-02-03\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-02-04\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-02-05\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-02-08\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-02-09\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-02-10\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-02-11\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-02-12\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-02-16\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-02-17\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-02-18\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-02-19\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-02-22\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-02-23\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-02-24\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-02-25\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-02-26\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-03-01\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-03-02\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-03-03\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-03-04\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-03-05\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-03-08\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-03-09\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-03-10\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-03-11\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-03-12\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-03-15\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-03-16\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-03-17\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-03-18\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-03-19\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-03-22\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-03-23\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-03-24\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-03-25\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-03-26\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-03-29\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-03-30\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-04-01\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-04-05\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-04-06\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-04-07\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-04-08\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-04-09\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-04-12\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-04-13\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-04-14\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-04-15\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-04-16\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-04-19\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-04-20\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-04-21\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-04-22\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-04-23\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-04-26\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-04-27\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-04-28\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-04-29\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-04-30\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-05-03\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-05-04\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-05-05\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-05-06\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-05-07\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-05-10\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-05-11\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-05-12\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-05-13\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-05-14\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-05-17\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-05-18\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-05-19\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-05-20\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-05-21\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-05-24\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-05-25\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-05-26\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-05-27\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-05-28\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-06-01\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-06-02\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-06-03\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-06-04\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-06-07\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-06-08\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-06-09\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-06-10\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-06-11\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-06-14\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-06-15\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-06-16\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-06-17\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-06-18\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-06-21\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-06-22\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-06-23\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-06-24\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-06-25\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-06-28\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-06-29\n",
      "Name: date, dtype: object\n",
      "finished 0    2021-06-30\n",
      "Name: date, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def price_df_from_response(res):\n",
    "    # initialize temp dataframe for batch of data in response\n",
    "    df = pd.DataFrame()\n",
    "    result = res.json()\n",
    "    df = df.append({\n",
    "         'status': result['status'],\n",
    "         'date': result['from'],\n",
    "         'open': result['open'],\n",
    "         'high': result['low'],\n",
    "         'close': result['close'],\n",
    "         'volume': result['volume'],\n",
    "         'afterHours': result['afterHours'],\n",
    "         'preMarket': result['preMarket']}, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "            \n",
    "key = \"FkJ0c2CuFs7HDQoJTSBaPXJdh_Mc90tU\"\n",
    "prices = pd.DataFrame()\n",
    "\n",
    "for month in [\"01\",\"02\",\"03\",\"04\",\"05\",\"06\"]:\n",
    "    if month in [\"01\",\"03\",\"05\",]:\n",
    "        last = 31\n",
    "    if month == \"02\":\n",
    "        last = 28\n",
    "    else:\n",
    "        last = 30\n",
    "    for day in range(1,last+1):\n",
    "        time.sleep(60)\n",
    "        if day < 10:\n",
    "            day_str = \"0\" + str(day)\n",
    "        else:\n",
    "            day_str = str(day)\n",
    "    \n",
    "        res = requests.get(f\"https://api.polygon.io/v1/open-close/GME/2021-{month}-{day_str}?adjusted=true&apiKey={key}\")\n",
    "        \n",
    "        \n",
    "        if res.status_code == 404:\n",
    "            # market was closed\n",
    "            continue\n",
    "        \n",
    "        else: \n",
    "            temp_df = price_df_from_response(res)\n",
    "            print(f\"finished {temp_df['date']}\")\n",
    "            prices = prices.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5a64b207",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices.to_csv(r\"C:\\Users\\Daniel\\Documents\\NLP Class\\Project\\gme_prices.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
