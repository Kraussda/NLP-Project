{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba934613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import emoji_def\n",
    "import Slang\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from itertools import combinations\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "if USE_CUDA:\n",
    "    DEVICE = torch.device('cuda')\n",
    "    print(\"Using cuda.\")\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    print(\"Using cpu.\")\n",
    "\n",
    "seed = 53113    \n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if USE_CUDA:\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47956939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive \n",
    "# drive.mount('/content/gdrive')\n",
    "# PATH = \"gdrive/My Drive/nlp21/Project/\"\n",
    "\n",
    "PATH = r'C:\\Users\\Daniel\\Documents\\NLP Class\\Project\\\\' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "154d778b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "if device == 'cpu':\n",
    "    VECTORS_CACHE_DIR = r'C:\\Users\\Daniel\\Documents\\NLP Class\\project\\.vector_cache'\n",
    "    # Please change above to your cache\n",
    "else:\n",
    "    VECTORS_CACHE_DIR = r'C:\\Users\\Daniel\\Documents\\NLP Class\\Project\\.vector_cache'\n",
    "    # This is the default cache on Colab. Caching may not work\n",
    "    # as expected on Colab.\n",
    "\n",
    "glove = GloVe(name='twitter.27B',dim=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4293361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>body</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>kind</th>\n",
       "      <th>parent</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>utc_raw</th>\n",
       "      <th>...</th>\n",
       "      <th>volume</th>\n",
       "      <th>move</th>\n",
       "      <th>month</th>\n",
       "      <th>body_lower</th>\n",
       "      <th>body_lower_no_punc</th>\n",
       "      <th>body_lower_no_punc_stop</th>\n",
       "      <th>body_lower_no_punc_stop_emoj</th>\n",
       "      <th>body_lower_no_punc_stop_emoj_lem</th>\n",
       "      <th>body_lower_no_punc_stop_emoj_lem_url</th>\n",
       "      <th>body_lower_no_punc_stop_emoj_lem_url_slang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>145755</td>\n",
       "      <td>166303</td>\n",
       "      <td>He sold for a 10 mil profit already. I like DV...</td>\n",
       "      <td>2021-03-29T19:58:14Z</td>\n",
       "      <td>gsr28j8</td>\n",
       "      <td>t2</td>\n",
       "      <td>t1_gsqpxip</td>\n",
       "      <td>GME</td>\n",
       "      <td>1.617066e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>10075068.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>he sold for a 10 mil profit already. i like dv...</td>\n",
       "      <td>he sold for a 10 mil profit already i like dvf...</td>\n",
       "      <td>sold 10 mil profit already like dvf dont under...</td>\n",
       "      <td>sold 10 mil profit already like dvf dont under...</td>\n",
       "      <td>sell 10 mil profit already like dvf dont under...</td>\n",
       "      <td>sell 10 mil profit already like dvf dont under...</td>\n",
       "      <td>sell 10 mil profit already like dvf dont under...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>406448</td>\n",
       "      <td>443440</td>\n",
       "      <td>Honestly, this shit got me up earlier, and goi...</td>\n",
       "      <td>2021-04-01T19:25:47Z</td>\n",
       "      <td>gt3bxxc</td>\n",
       "      <td>t2</td>\n",
       "      <td>t3_mi3eli</td>\n",
       "      <td>GME</td>\n",
       "      <td>1.617323e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>9351417.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>honestly, this shit got me up earlier, and goi...</td>\n",
       "      <td>honestly this shit got me up earlier and going...</td>\n",
       "      <td>honestly shit got earlier going bed earlier pu...</td>\n",
       "      <td>honestly shit got earlier going bed earlier pu...</td>\n",
       "      <td>honestly shit get earlier go bed earlier put u...</td>\n",
       "      <td>honestly shit get earlier go bed earlier put u...</td>\n",
       "      <td>honestly shit get earlier go bed earlier put u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>226054</td>\n",
       "      <td>673216</td>\n",
       "      <td>I appreciate the confidence. I will try this w...</td>\n",
       "      <td>2021-03-11T19:02:09Z</td>\n",
       "      <td>gqn11oa</td>\n",
       "      <td>t2</td>\n",
       "      <td>t1_gqmz84n</td>\n",
       "      <td>GME</td>\n",
       "      <td>1.615511e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>28402777.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>i appreciate the confidence. i will try this w...</td>\n",
       "      <td>i appreciate the confidence i will try this wh...</td>\n",
       "      <td>appreciate confidence try next see</td>\n",
       "      <td>appreciate confidence try next see</td>\n",
       "      <td>appreciate confidence try next see</td>\n",
       "      <td>appreciate confidence try next see</td>\n",
       "      <td>appreciate confidence try next see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>319915</td>\n",
       "      <td>1091065</td>\n",
       "      <td>Insider knowledge. Shill idiot doesn't realize...</td>\n",
       "      <td>2021-03-03T17:12:10Z</td>\n",
       "      <td>gplau59</td>\n",
       "      <td>t2</td>\n",
       "      <td>t3_lwuqgq</td>\n",
       "      <td>GME</td>\n",
       "      <td>1.614813e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>19325198.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>insider knowledge. shill idiot doesn't realize...</td>\n",
       "      <td>insider knowledge shill idiot doesnt realize t...</td>\n",
       "      <td>insider knowledge shill idiot doesnt realize c...</td>\n",
       "      <td>insider knowledge shill idiot doesnt realize c...</td>\n",
       "      <td>insider knowledge shill idiot doesnt realize c...</td>\n",
       "      <td>insider knowledge shill idiot doesnt realize c...</td>\n",
       "      <td>insider knowledge shill idiot doesnt realize c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>400977</td>\n",
       "      <td>259725</td>\n",
       "      <td>Mods r fuk üåàüêª</td>\n",
       "      <td>2021-04-05T17:06:11Z</td>\n",
       "      <td>gti44np</td>\n",
       "      <td>t2</td>\n",
       "      <td>t3_mkizw4</td>\n",
       "      <td>GME</td>\n",
       "      <td>1.617660e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>14223605.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>mods r fuk üåàüêª</td>\n",
       "      <td>mods r fuk üåàüêª</td>\n",
       "      <td>mods r fuk üåàüêª</td>\n",
       "      <td>mods r fuk</td>\n",
       "      <td>mod r fuk</td>\n",
       "      <td>mod r fuk</td>\n",
       "      <td>mod r fuk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0_x  \\\n",
       "0           0        145755        166303   \n",
       "1           1        406448        443440   \n",
       "2           2        226054        673216   \n",
       "3           3        319915       1091065   \n",
       "4           4        400977        259725   \n",
       "\n",
       "                                                body           created_utc  \\\n",
       "0  He sold for a 10 mil profit already. I like DV...  2021-03-29T19:58:14Z   \n",
       "1  Honestly, this shit got me up earlier, and goi...  2021-04-01T19:25:47Z   \n",
       "2  I appreciate the confidence. I will try this w...  2021-03-11T19:02:09Z   \n",
       "3  Insider knowledge. Shill idiot doesn't realize...  2021-03-03T17:12:10Z   \n",
       "4                                      Mods r fuk üåàüêª  2021-04-05T17:06:11Z   \n",
       "\n",
       "        id kind      parent subreddit       utc_raw  ...      volume move  \\\n",
       "0  gsr28j8   t2  t1_gsqpxip       GME  1.617066e+09  ...  10075068.0    1   \n",
       "1  gt3bxxc   t2   t3_mi3eli       GME  1.617323e+09  ...   9351417.0   -1   \n",
       "2  gqn11oa   t2  t1_gqmz84n       GME  1.615511e+09  ...  28402777.0    1   \n",
       "3  gplau59   t2   t3_lwuqgq       GME  1.614813e+09  ...  19325198.0    1   \n",
       "4  gti44np   t2   t3_mkizw4       GME  1.617660e+09  ...  14223605.0    1   \n",
       "\n",
       "  month                                         body_lower  \\\n",
       "0     3  he sold for a 10 mil profit already. i like dv...   \n",
       "1     4  honestly, this shit got me up earlier, and goi...   \n",
       "2     3  i appreciate the confidence. i will try this w...   \n",
       "3     3  insider knowledge. shill idiot doesn't realize...   \n",
       "4     4                                      mods r fuk üåàüêª   \n",
       "\n",
       "                                  body_lower_no_punc  \\\n",
       "0  he sold for a 10 mil profit already i like dvf...   \n",
       "1  honestly this shit got me up earlier and going...   \n",
       "2  i appreciate the confidence i will try this wh...   \n",
       "3  insider knowledge shill idiot doesnt realize t...   \n",
       "4                                      mods r fuk üåàüêª   \n",
       "\n",
       "                             body_lower_no_punc_stop  \\\n",
       "0  sold 10 mil profit already like dvf dont under...   \n",
       "1  honestly shit got earlier going bed earlier pu...   \n",
       "2                 appreciate confidence try next see   \n",
       "3  insider knowledge shill idiot doesnt realize c...   \n",
       "4                                      mods r fuk üåàüêª   \n",
       "\n",
       "                        body_lower_no_punc_stop_emoj  \\\n",
       "0  sold 10 mil profit already like dvf dont under...   \n",
       "1  honestly shit got earlier going bed earlier pu...   \n",
       "2                 appreciate confidence try next see   \n",
       "3  insider knowledge shill idiot doesnt realize c...   \n",
       "4                                        mods r fuk    \n",
       "\n",
       "                    body_lower_no_punc_stop_emoj_lem  \\\n",
       "0  sell 10 mil profit already like dvf dont under...   \n",
       "1  honestly shit get earlier go bed earlier put u...   \n",
       "2                 appreciate confidence try next see   \n",
       "3  insider knowledge shill idiot doesnt realize c...   \n",
       "4                                          mod r fuk   \n",
       "\n",
       "                body_lower_no_punc_stop_emoj_lem_url  \\\n",
       "0  sell 10 mil profit already like dvf dont under...   \n",
       "1  honestly shit get earlier go bed earlier put u...   \n",
       "2                 appreciate confidence try next see   \n",
       "3  insider knowledge shill idiot doesnt realize c...   \n",
       "4                                          mod r fuk   \n",
       "\n",
       "          body_lower_no_punc_stop_emoj_lem_url_slang  \n",
       "0  sell 10 mil profit already like dvf dont under...  \n",
       "1  honestly shit get earlier go bed earlier put u...  \n",
       "2                 appreciate confidence try next see  \n",
       "3  insider knowledge shill idiot doesnt realize c...  \n",
       "4                                          mod r fuk  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(PATH + \"train_dev_same_date_clean.csv\")\n",
    "valid_data = pd.read_csv(PATH + \"test_dev_same_date_clean.csv\")\n",
    "\n",
    "train_iter = list(zip(train_data['move'],train_data['body_lower_no_punc_stop_emoj_lem_url_slang'].astype(str)))\n",
    "valid_iter = list(zip(valid_data['move'],valid_data['body_lower_no_punc_stop_emoj_lem_url_slang'].astype(str)))\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63345324",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"count\"] = train_data[\"body_lower_no_punc_stop_emoj_lem_url_slang\"].apply(lambda text: len(tokenizer(str(text))))\n",
    "valid_data[\"count\"] = valid_data[\"body_lower_no_punc_stop_emoj_lem_url_slang\"].apply(lambda text: len(tokenizer(str(text))))\n",
    "\n",
    "model_d = max(max(valid_data[\"count\"]),max(train_data[\"count\"]))\n",
    "\n",
    "train_data[\"tokens\"] = train_data[\"body_lower_no_punc_stop_emoj_lem_url_slang\"].apply(lambda text: tokenizer(str(text)))\n",
    "valid_data[\"tokens\"] = valid_data[\"body_lower_no_punc_stop_emoj_lem_url_slang\"].apply(lambda text: tokenizer(str(text)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "31594735",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "def collate_into_embed(batch):\n",
    "\n",
    "    labels = torch.zeros(len(batch))\n",
    "    examples = torch.zeros(len(batch),model_d, 200)\n",
    "    \n",
    "    for i in range(len(batch)):\n",
    "        example = batch[i]\n",
    "        label = example[0]\n",
    "        if label == -1:\n",
    "            label = 0\n",
    "        words = tokenizer(example[1])\n",
    "        vecs = glove.get_vecs_by_tokens(words)\n",
    "        \n",
    "        labels[i] = label\n",
    "        examples[i,:len(vecs)] =  vecs\n",
    "    \n",
    "    return labels, examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "49717e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guidance from https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/3_cnn.ipynb\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "                \n",
    "        #self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "                \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        #embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = text.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "                \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d18d5491",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.NLLLoss()\n",
    "\n",
    "def train_an_epoch(dataloader):\n",
    "    model.train() # Sets the module in training mode.\n",
    "    log_interval = 500\n",
    "\n",
    "    for idx, (label, text) in enumerate(dataloader):\n",
    "        model.zero_grad()\n",
    "        log_probs = model(text)\n",
    "        loss = loss_function(log_probs, label.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            print(f'At iteration {idx} the loss is {loss:.3f}.')\n",
    "            \n",
    "def get_accuracy(dataloader):\n",
    "    hits = 0\n",
    "    tot = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            examples = batch[1]\n",
    "            labels = batch[0]\n",
    "            tot += len(labels)\n",
    "            estimate = model.forward(examples)\n",
    "            pred = torch.argmax(estimate, dim=1)\n",
    "            # there's probably a better way to do this\n",
    "            output = labels - pred\n",
    "            for x in range(len(labels)):\n",
    "                if (labels[x] == 0 and pred[x] == 0) or (labels[x] == 1 and pred[x] == 1):\n",
    "                    hits +=1\n",
    "            \n",
    "    return hits/tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "90808789",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, \n",
    "                              collate_fn=collate_into_embed)\n",
    "valid_dataloader = DataLoader(valid_iter, batch_size=BATCH_SIZE,\n",
    "                              shuffle=False, \n",
    "                              collate_fn=collate_into_embed)\n",
    "\n",
    "#vocab_size = len(vocab)\n",
    "vocab_size = 0\n",
    "embedding_dim = 200\n",
    "n_filters = 100\n",
    "filter_sizes = [3,5,7]\n",
    "output_dim = 2\n",
    "dropout_rate = 0.25\n",
    "pad_index = 0\n",
    "\n",
    "model = CNN(vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout_rate, pad_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c19008a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-2692033b970f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mepoch_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtrain_an_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtrain_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-65-7b4c68928142>\u001b[0m in \u001b[0;36mtrain_an_epoch\u001b[1;34m(dataloader)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mlog_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-61-302e8d030d52>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m#embedded = [batch size, 1, sent len, emb dim]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mconved\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m#conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-61-302e8d030d52>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m#embedded = [batch size, 1, sent len, emb dim]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mconved\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m#conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[1;32m--> 396\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 100 # epoch\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "accuracies=[]\n",
    "train_accuracies=[]\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train_an_epoch(train_dataloader)\n",
    "    accuracy = get_accuracy(valid_dataloader)\n",
    "    train_accuracy = get_accuracy(train_dataloader)\n",
    "    accuracies.append(accuracy)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    time_taken = time.time() - epoch_start_time\n",
    "    print()\n",
    "    print(f'After epoch {epoch} the validation accuracy is {accuracy:.3f}.')\n",
    "    print(f'After epoch {epoch} the training accuracy is {train_accuracy:.3f}.')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
