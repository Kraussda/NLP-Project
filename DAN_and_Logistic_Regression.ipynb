{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "r9WWPYwMphyt",
   "metadata": {
    "id": "r9WWPYwMphyt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458faaa2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "458faaa2",
    "outputId": "51e7451d-d5a5-444e-93fe-a475ba05a5f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext==0.9.0\n",
      "  Downloading torchtext-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.1 MB 33.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (2.23.0)\n",
      "Collecting torch==1.8.0\n",
      "  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 735.5 MB 10 kB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (1.19.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (4.41.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->torchtext==0.9.0) (3.7.4.3)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (2.10)\n",
      "Installing collected packages: torch, torchtext\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.9.0+cu102\n",
      "    Uninstalling torch-1.9.0+cu102:\n",
      "      Successfully uninstalled torch-1.9.0+cu102\n",
      "  Attempting uninstall: torchtext\n",
      "    Found existing installation: torchtext 0.10.0\n",
      "    Uninstalling torchtext-0.10.0:\n",
      "      Successfully uninstalled torchtext-0.10.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.10.0+cu102 requires torch==1.9.0, but you have torch 1.8.0 which is incompatible.\u001b[0m\n",
      "Successfully installed torch-1.8.0 torchtext-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "D4RADSa8pbDP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D4RADSa8pbDP",
    "outputId": "4b092ebf-261c-4cb5-ceff-6e2f25e3bb2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import emoji_def\n",
    "import Slang\n",
    "import re\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from itertools import combinations\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "if USE_CUDA:\n",
    "    DEVICE = torch.device('cuda')\n",
    "    print(\"Using cuda.\")\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    print(\"Using cpu.\")\n",
    "\n",
    "seed = 53113    \n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if USE_CUDA:\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85854482",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "85854482",
    "outputId": "adcb921e-f849-4c33-9ea1-61f1e23360b6"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive \n",
    "# drive.mount('/content/gdrive')\n",
    "# PATH = \"gdrive/My Drive/nlp21/Project/\"\n",
    "\n",
    "PATH = r'C:\\Users\\Daniel\\Documents\\NLP Class\\Project\\\\' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06877643",
   "metadata": {
    "id": "06877643"
   },
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "if device == 'cpu':\n",
    "    VECTORS_CACHE_DIR = r'C:\\Users\\Daniel\\Documents\\NLP Class'\n",
    "    # Please change above to your cache\n",
    "else:\n",
    "    VECTORS_CACHE_DIR = r'C:\\Users\\Daniel\\Documents\\NLP Class\\Project\\.vector_cache'\n",
    "    # This is the default cache on Colab. Caching may not work\n",
    "    # as expected on Colab.\n",
    "    \n",
    "#VECTORS_CACHE_DIR = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7446a53",
   "metadata": {
    "id": "e7446a53"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(PATH + \"train_small_same_date_clean.csv\")\n",
    "valid_data = pd.read_csv(PATH + \"test_small_same_date_clean.csv\")\n",
    "\n",
    "train_iter = list(zip(train_data['move'],train_data['body_lower_no_punc_stop_emoj_lem_url_slang'].astype(str)))\n",
    "valid_iter = list(zip(valid_data['move'],valid_data['body_lower_no_punc_stop_emoj_lem_url_slang'].astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6b033342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                                                 1000\n",
       "Unnamed: 0.1                                                                             337852\n",
       "Unnamed: 0_x                                                                            1152545\n",
       "body                                                       Yessss i just got 33 more sharesðŸ’ŽðŸ™ŒðŸ™ŒðŸ™Œ\n",
       "created_utc                                                                2021-03-02T14:46:23Z\n",
       "id                                                                                      gpggmme\n",
       "kind                                                                                         t2\n",
       "parent                                                                                t3_lwc2uk\n",
       "subreddit                                                                                   GME\n",
       "utc_raw                                                                            1614717983.0\n",
       "utc_dt                                                                2021-03-02 14:46:23+00:00\n",
       "eastern_dt                                                            2021-03-02 09:46:23-05:00\n",
       "date                                                                                 2021-03-02\n",
       "tomorrow                                                                             2021-03-03\n",
       "tokenized                                     ['yessss', 'i', 'just', 'got', '33', 'more', '...\n",
       "length                                                                                        7\n",
       "Unnamed: 0_y                                                                                  0\n",
       "afterHours                                                                                120.0\n",
       "close                                                                                    118.18\n",
       "high                                                                                      112.2\n",
       "open                                                                                     116.93\n",
       "preMarket                                                                                117.25\n",
       "status                                                                                       OK\n",
       "volume                                                                               33873525.0\n",
       "move                                                                                          1\n",
       "month                                                                                         3\n",
       "body_lower                                                 yessss i just got 33 more sharesðŸ’ŽðŸ™ŒðŸ™ŒðŸ™Œ\n",
       "body_lower_no_punc                                         yessss i just got 33 more sharesðŸ’ŽðŸ™ŒðŸ™ŒðŸ™Œ\n",
       "body_lower_no_punc_stop                                                yessss got 33 sharesðŸ’ŽðŸ™ŒðŸ™ŒðŸ™Œ\n",
       "body_lower_no_punc_stop_emoj                                               yessss got 33 shares\n",
       "body_lower_no_punc_stop_emoj_lem                                               yes get 33 share\n",
       "body_lower_no_punc_stop_emoj_lem_url                                           yes get 33 share\n",
       "body_lower_no_punc_stop_emoj_lem_url_slang                                     yes get 33 share\n",
       "Name: 1000, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.iloc[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eaef7a75",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eaef7a75",
    "outputId": "49df2a9b-e2d7-4489-e327-b3bba940dc3d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1193513/1193514 [01:55<00:00, 10360.99it/s]\n"
     ]
    }
   ],
   "source": [
    "glove = GloVe(name='twitter.27B',dim=200) # could not find 300d version of these embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "537811b9",
   "metadata": {
    "id": "537811b9"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "def collate_into_cbow(batch):\n",
    "\n",
    "    labels = torch.zeros(len(batch))\n",
    "    examples = torch.zeros(len(batch), 200)\n",
    "    \n",
    "    for i in range(len(batch)):\n",
    "        example = batch[i]\n",
    "        label = example[0]\n",
    "        if label == -1:\n",
    "            label = 0\n",
    "        words = tokenizer(example[1])\n",
    "        vecs = glove.get_vecs_by_tokens(words)\n",
    "        summed = vecs.sum(axis=0).reshape(1,-1)\n",
    "        labels[i] = label\n",
    "        examples[i] = summed # change to average\n",
    "    \n",
    "    return labels, examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4df5a14",
   "metadata": {
    "id": "d4df5a14"
   },
   "outputs": [],
   "source": [
    "class LogRegClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LogRegClassifier, self).__init__()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.linear = nn.Linear(200, 2,)\n",
    "\n",
    "    def forward(self, bow_vec):\n",
    "        return F.log_softmax(self.sigmoid(self.linear(bow_vec)), dim=1)\n",
    "    \n",
    "class DANClassifier(nn.Module):\n",
    "    '''Using Iyyers specs of 3 300-d linear layers with ReLU activation'''\n",
    "    def __init__(self):\n",
    "        # calls the init function of nn.Module.  Dont get confused by syntax,\n",
    "        # just always do it in an nn.Module\n",
    "        super(DANClassifier, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(200, 200,)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(200,200,)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.linear3 = nn.Linear(200,2,)\n",
    "\n",
    "    def forward(self, bow_vec):\n",
    "        return F.log_softmax(\n",
    "            self.linear3(\n",
    "                self.relu2(\n",
    "                    self.linear2(\n",
    "                        self.relu1(\n",
    "                            self.linear1(bow_vec)\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            ), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a39eafb",
   "metadata": {
    "id": "7a39eafb"
   },
   "outputs": [],
   "source": [
    "loss_function = torch.nn.NLLLoss()\n",
    "\n",
    "def train_an_epoch(dataloader):\n",
    "    model.train() # Sets the module in training mode.\n",
    "    log_interval = 500\n",
    "\n",
    "    for idx, (label, text) in enumerate(dataloader):\n",
    "        model.zero_grad()\n",
    "        log_probs = model(text)\n",
    "        loss = loss_function(log_probs, label.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            print(f'At iteration {idx} the loss is {loss:.3f}.')\n",
    "            \n",
    "def get_accuracy(dataloader):\n",
    "    hits = 0\n",
    "    tot = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            examples = batch[1]\n",
    "            labels = batch[0]\n",
    "            tot += len(labels)\n",
    "            estimate = model.forward(examples)\n",
    "            pred = torch.argmax(estimate, dim=1)\n",
    "            # there's probably a better way to do this\n",
    "            output = labels - pred\n",
    "            for x in range(len(labels)):\n",
    "                if (labels[x] == 0 and pred[x] == 0) or (labels[x] == 1 and pred[x] == 1):\n",
    "                    hits +=1\n",
    "            \n",
    "    return hits/tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4d8e6050",
   "metadata": {
    "id": "4d8e6050"
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, \n",
    "                              collate_fn=collate_into_cbow)\n",
    "valid_dataloader = DataLoader(valid_iter, batch_size=BATCH_SIZE,\n",
    "                              shuffle=False, \n",
    "                              collate_fn=collate_into_cbow)\n",
    "\n",
    "model = DANClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b9f65878",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b9f65878",
    "outputId": "9bb61534-6927-4eaf-f667-0720ff3b4f90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 500 the loss is 0.589.\n",
      "At iteration 1000 the loss is 0.608.\n",
      "At iteration 1500 the loss is 0.584.\n",
      "At iteration 2000 the loss is 0.588.\n",
      "At iteration 2500 the loss is 0.693.\n",
      "At iteration 3000 the loss is 0.651.\n",
      "At iteration 3500 the loss is 0.610.\n",
      "\n",
      "After epoch 1 the validation accuracy is 0.369.\n",
      "After epoch 1 the training accuracy is 0.674.\n",
      "\n",
      "At iteration 500 the loss is 0.540.\n",
      "At iteration 1000 the loss is 0.613.\n",
      "At iteration 1500 the loss is 0.654.\n",
      "At iteration 2000 the loss is 0.569.\n",
      "At iteration 2500 the loss is 0.658.\n",
      "At iteration 3000 the loss is 0.663.\n",
      "At iteration 3500 the loss is 0.596.\n",
      "\n",
      "After epoch 2 the validation accuracy is 0.369.\n",
      "After epoch 2 the training accuracy is 0.676.\n",
      "\n",
      "At iteration 500 the loss is 0.615.\n",
      "At iteration 1000 the loss is 0.542.\n",
      "At iteration 1500 the loss is 0.672.\n",
      "At iteration 2000 the loss is 0.609.\n",
      "At iteration 2500 the loss is 0.638.\n",
      "At iteration 3000 the loss is 0.661.\n",
      "At iteration 3500 the loss is 0.607.\n",
      "\n",
      "After epoch 3 the validation accuracy is 0.375.\n",
      "After epoch 3 the training accuracy is 0.680.\n",
      "\n",
      "At iteration 500 the loss is 0.604.\n",
      "At iteration 1000 the loss is 0.587.\n",
      "At iteration 1500 the loss is 0.619.\n",
      "At iteration 2000 the loss is 0.599.\n",
      "At iteration 2500 the loss is 0.567.\n",
      "At iteration 3000 the loss is 0.594.\n",
      "At iteration 3500 the loss is 0.745.\n",
      "\n",
      "After epoch 4 the validation accuracy is 0.376.\n",
      "After epoch 4 the training accuracy is 0.681.\n",
      "\n",
      "At iteration 500 the loss is 0.633.\n",
      "At iteration 1000 the loss is 0.585.\n",
      "At iteration 1500 the loss is 0.634.\n",
      "At iteration 2000 the loss is 0.647.\n",
      "At iteration 2500 the loss is 0.615.\n",
      "At iteration 3000 the loss is 0.575.\n",
      "At iteration 3500 the loss is 0.614.\n",
      "\n",
      "After epoch 5 the validation accuracy is 0.387.\n",
      "After epoch 5 the training accuracy is 0.684.\n",
      "\n",
      "At iteration 500 the loss is 0.713.\n",
      "At iteration 1000 the loss is 0.718.\n",
      "At iteration 1500 the loss is 0.532.\n",
      "At iteration 2000 the loss is 0.654.\n",
      "At iteration 2500 the loss is 0.643.\n",
      "At iteration 3000 the loss is 0.641.\n",
      "At iteration 3500 the loss is 0.517.\n",
      "\n",
      "After epoch 6 the validation accuracy is 0.377.\n",
      "After epoch 6 the training accuracy is 0.687.\n",
      "\n",
      "At iteration 500 the loss is 0.590.\n",
      "At iteration 1000 the loss is 0.595.\n",
      "At iteration 1500 the loss is 0.569.\n",
      "At iteration 2000 the loss is 0.594.\n",
      "At iteration 2500 the loss is 0.611.\n",
      "At iteration 3000 the loss is 0.546.\n",
      "At iteration 3500 the loss is 0.622.\n",
      "\n",
      "After epoch 7 the validation accuracy is 0.382.\n",
      "After epoch 7 the training accuracy is 0.691.\n",
      "\n",
      "At iteration 500 the loss is 0.590.\n",
      "At iteration 1000 the loss is 0.512.\n",
      "At iteration 1500 the loss is 0.606.\n",
      "At iteration 2000 the loss is 0.610.\n",
      "At iteration 2500 the loss is 0.635.\n",
      "At iteration 3000 the loss is 0.496.\n",
      "At iteration 3500 the loss is 0.617.\n",
      "\n",
      "After epoch 8 the validation accuracy is 0.381.\n",
      "After epoch 8 the training accuracy is 0.693.\n",
      "\n",
      "At iteration 500 the loss is 0.555.\n",
      "At iteration 1000 the loss is 0.579.\n",
      "At iteration 1500 the loss is 0.614.\n",
      "At iteration 2000 the loss is 0.609.\n",
      "At iteration 2500 the loss is 0.534.\n",
      "At iteration 3000 the loss is 0.593.\n",
      "At iteration 3500 the loss is 0.602.\n",
      "\n",
      "After epoch 9 the validation accuracy is 0.382.\n",
      "After epoch 9 the training accuracy is 0.696.\n",
      "\n",
      "At iteration 500 the loss is 0.524.\n",
      "At iteration 1000 the loss is 0.575.\n",
      "At iteration 1500 the loss is 0.523.\n",
      "At iteration 2000 the loss is 0.649.\n",
      "At iteration 2500 the loss is 0.552.\n",
      "At iteration 3000 the loss is 0.563.\n",
      "At iteration 3500 the loss is 0.630.\n",
      "\n",
      "After epoch 10 the validation accuracy is 0.390.\n",
      "After epoch 10 the training accuracy is 0.702.\n",
      "\n",
      "At iteration 500 the loss is 0.506.\n",
      "At iteration 1000 the loss is 0.628.\n",
      "At iteration 1500 the loss is 0.598.\n",
      "At iteration 2000 the loss is 0.579.\n",
      "At iteration 2500 the loss is 0.583.\n",
      "At iteration 3000 the loss is 0.531.\n",
      "At iteration 3500 the loss is 0.620.\n",
      "\n",
      "After epoch 11 the validation accuracy is 0.385.\n",
      "After epoch 11 the training accuracy is 0.703.\n",
      "\n",
      "At iteration 500 the loss is 0.550.\n",
      "At iteration 1000 the loss is 0.608.\n",
      "At iteration 1500 the loss is 0.697.\n",
      "At iteration 2000 the loss is 0.574.\n",
      "At iteration 2500 the loss is 0.599.\n",
      "At iteration 3000 the loss is 0.622.\n",
      "At iteration 3500 the loss is 0.489.\n",
      "\n",
      "After epoch 12 the validation accuracy is 0.398.\n",
      "After epoch 12 the training accuracy is 0.711.\n",
      "\n",
      "At iteration 500 the loss is 0.585.\n",
      "At iteration 1000 the loss is 0.475.\n",
      "At iteration 1500 the loss is 0.606.\n",
      "At iteration 2000 the loss is 0.552.\n",
      "At iteration 2500 the loss is 0.469.\n",
      "At iteration 3000 the loss is 0.601.\n",
      "At iteration 3500 the loss is 0.657.\n",
      "\n",
      "After epoch 13 the validation accuracy is 0.397.\n",
      "After epoch 13 the training accuracy is 0.713.\n",
      "\n",
      "At iteration 500 the loss is 0.553.\n",
      "At iteration 1000 the loss is 0.504.\n",
      "At iteration 1500 the loss is 0.565.\n",
      "At iteration 2000 the loss is 0.572.\n",
      "At iteration 2500 the loss is 0.549.\n",
      "At iteration 3000 the loss is 0.596.\n",
      "At iteration 3500 the loss is 0.607.\n",
      "\n",
      "After epoch 14 the validation accuracy is 0.401.\n",
      "After epoch 14 the training accuracy is 0.719.\n",
      "\n",
      "At iteration 500 the loss is 0.611.\n",
      "At iteration 1000 the loss is 0.521.\n",
      "At iteration 1500 the loss is 0.601.\n",
      "At iteration 2000 the loss is 0.589.\n",
      "At iteration 2500 the loss is 0.501.\n",
      "At iteration 3000 the loss is 0.555.\n",
      "At iteration 3500 the loss is 0.524.\n",
      "\n",
      "After epoch 15 the validation accuracy is 0.399.\n",
      "After epoch 15 the training accuracy is 0.722.\n",
      "\n",
      "At iteration 500 the loss is 0.613.\n",
      "At iteration 1000 the loss is 0.474.\n",
      "At iteration 1500 the loss is 0.565.\n",
      "At iteration 2000 the loss is 0.553.\n",
      "At iteration 2500 the loss is 0.489.\n",
      "At iteration 3000 the loss is 0.519.\n",
      "At iteration 3500 the loss is 0.698.\n",
      "\n",
      "After epoch 16 the validation accuracy is 0.400.\n",
      "After epoch 16 the training accuracy is 0.726.\n",
      "\n",
      "At iteration 500 the loss is 0.498.\n",
      "At iteration 1000 the loss is 0.448.\n",
      "At iteration 1500 the loss is 0.467.\n",
      "At iteration 2000 the loss is 0.588.\n",
      "At iteration 2500 the loss is 0.541.\n",
      "At iteration 3000 the loss is 0.565.\n",
      "At iteration 3500 the loss is 0.481.\n",
      "\n",
      "After epoch 17 the validation accuracy is 0.409.\n",
      "After epoch 17 the training accuracy is 0.731.\n",
      "\n",
      "At iteration 500 the loss is 0.576.\n",
      "At iteration 1000 the loss is 0.524.\n",
      "At iteration 1500 the loss is 0.544.\n",
      "At iteration 2000 the loss is 0.445.\n",
      "At iteration 2500 the loss is 0.556.\n",
      "At iteration 3000 the loss is 0.549.\n",
      "At iteration 3500 the loss is 0.541.\n",
      "\n",
      "After epoch 18 the validation accuracy is 0.414.\n",
      "After epoch 18 the training accuracy is 0.733.\n",
      "\n",
      "At iteration 500 the loss is 0.607.\n",
      "At iteration 1000 the loss is 0.527.\n",
      "At iteration 1500 the loss is 0.561.\n",
      "At iteration 2000 the loss is 0.580.\n",
      "At iteration 2500 the loss is 0.551.\n",
      "At iteration 3000 the loss is 0.712.\n",
      "At iteration 3500 the loss is 0.523.\n",
      "\n",
      "After epoch 19 the validation accuracy is 0.408.\n",
      "After epoch 19 the training accuracy is 0.739.\n",
      "\n",
      "At iteration 500 the loss is 0.513.\n",
      "At iteration 1000 the loss is 0.421.\n",
      "At iteration 1500 the loss is 0.503.\n",
      "At iteration 2000 the loss is 0.494.\n",
      "At iteration 2500 the loss is 0.659.\n",
      "At iteration 3000 the loss is 0.553.\n",
      "At iteration 3500 the loss is 0.649.\n",
      "\n",
      "After epoch 20 the validation accuracy is 0.413.\n",
      "After epoch 20 the training accuracy is 0.742.\n",
      "\n",
      "At iteration 500 the loss is 0.449.\n",
      "At iteration 1000 the loss is 0.463.\n",
      "At iteration 1500 the loss is 0.457.\n",
      "At iteration 2000 the loss is 0.573.\n",
      "At iteration 2500 the loss is 0.605.\n",
      "At iteration 3000 the loss is 0.509.\n",
      "At iteration 3500 the loss is 0.560.\n",
      "\n",
      "After epoch 21 the validation accuracy is 0.404.\n",
      "After epoch 21 the training accuracy is 0.742.\n",
      "\n",
      "At iteration 500 the loss is 0.499.\n",
      "At iteration 1000 the loss is 0.532.\n",
      "At iteration 1500 the loss is 0.554.\n",
      "At iteration 2000 the loss is 0.475.\n",
      "At iteration 2500 the loss is 0.610.\n",
      "At iteration 3000 the loss is 0.488.\n",
      "At iteration 3500 the loss is 0.689.\n",
      "\n",
      "After epoch 22 the validation accuracy is 0.410.\n",
      "After epoch 22 the training accuracy is 0.747.\n",
      "\n",
      "At iteration 500 the loss is 0.548.\n",
      "At iteration 1000 the loss is 0.596.\n",
      "At iteration 1500 the loss is 0.551.\n",
      "At iteration 2000 the loss is 0.547.\n",
      "At iteration 2500 the loss is 0.384.\n",
      "At iteration 3000 the loss is 0.445.\n",
      "At iteration 3500 the loss is 0.531.\n",
      "\n",
      "After epoch 23 the validation accuracy is 0.400.\n",
      "After epoch 23 the training accuracy is 0.744.\n",
      "\n",
      "At iteration 500 the loss is 0.481.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 1000 the loss is 0.446.\n",
      "At iteration 1500 the loss is 0.423.\n",
      "At iteration 2000 the loss is 0.411.\n",
      "At iteration 2500 the loss is 0.584.\n",
      "At iteration 3000 the loss is 0.476.\n",
      "At iteration 3500 the loss is 0.540.\n",
      "\n",
      "After epoch 24 the validation accuracy is 0.407.\n",
      "After epoch 24 the training accuracy is 0.752.\n",
      "\n",
      "At iteration 500 the loss is 0.501.\n",
      "At iteration 1000 the loss is 0.588.\n",
      "At iteration 1500 the loss is 0.508.\n",
      "At iteration 2000 the loss is 0.528.\n",
      "At iteration 2500 the loss is 0.566.\n",
      "At iteration 3000 the loss is 0.490.\n",
      "At iteration 3500 the loss is 0.536.\n",
      "\n",
      "After epoch 25 the validation accuracy is 0.419.\n",
      "After epoch 25 the training accuracy is 0.757.\n",
      "\n",
      "At iteration 500 the loss is 0.461.\n",
      "At iteration 1000 the loss is 0.482.\n",
      "At iteration 1500 the loss is 0.525.\n",
      "At iteration 2000 the loss is 0.465.\n",
      "At iteration 2500 the loss is 0.415.\n",
      "At iteration 3000 the loss is 0.624.\n",
      "At iteration 3500 the loss is 0.565.\n",
      "\n",
      "After epoch 26 the validation accuracy is 0.412.\n",
      "After epoch 26 the training accuracy is 0.759.\n",
      "\n",
      "At iteration 500 the loss is 0.418.\n",
      "At iteration 1000 the loss is 0.450.\n",
      "At iteration 1500 the loss is 0.473.\n",
      "At iteration 2000 the loss is 0.530.\n",
      "At iteration 2500 the loss is 0.556.\n",
      "At iteration 3000 the loss is 0.467.\n",
      "At iteration 3500 the loss is 0.627.\n",
      "\n",
      "After epoch 27 the validation accuracy is 0.428.\n",
      "After epoch 27 the training accuracy is 0.763.\n",
      "\n",
      "At iteration 500 the loss is 0.539.\n",
      "At iteration 1000 the loss is 0.479.\n",
      "At iteration 1500 the loss is 0.575.\n",
      "At iteration 2000 the loss is 0.512.\n",
      "At iteration 2500 the loss is 0.479.\n",
      "At iteration 3000 the loss is 0.444.\n",
      "At iteration 3500 the loss is 0.367.\n",
      "\n",
      "After epoch 28 the validation accuracy is 0.419.\n",
      "After epoch 28 the training accuracy is 0.765.\n",
      "\n",
      "At iteration 500 the loss is 0.523.\n",
      "At iteration 1000 the loss is 0.446.\n",
      "At iteration 1500 the loss is 0.438.\n",
      "At iteration 2000 the loss is 0.444.\n",
      "At iteration 2500 the loss is 0.491.\n",
      "At iteration 3000 the loss is 0.575.\n",
      "At iteration 3500 the loss is 0.430.\n",
      "\n",
      "After epoch 29 the validation accuracy is 0.423.\n",
      "After epoch 29 the training accuracy is 0.768.\n",
      "\n",
      "At iteration 500 the loss is 0.503.\n",
      "At iteration 1000 the loss is 0.391.\n",
      "At iteration 1500 the loss is 0.583.\n",
      "At iteration 2000 the loss is 0.312.\n",
      "At iteration 2500 the loss is 0.552.\n",
      "At iteration 3000 the loss is 0.476.\n",
      "At iteration 3500 the loss is 0.395.\n",
      "\n",
      "After epoch 30 the validation accuracy is 0.417.\n",
      "After epoch 30 the training accuracy is 0.771.\n",
      "\n",
      "At iteration 500 the loss is 0.507.\n",
      "At iteration 1000 the loss is 0.467.\n",
      "At iteration 1500 the loss is 0.418.\n",
      "At iteration 2000 the loss is 0.520.\n",
      "At iteration 2500 the loss is 0.605.\n",
      "At iteration 3000 the loss is 0.588.\n",
      "At iteration 3500 the loss is 0.457.\n",
      "\n",
      "After epoch 31 the validation accuracy is 0.416.\n",
      "After epoch 31 the training accuracy is 0.767.\n",
      "\n",
      "At iteration 500 the loss is 0.399.\n",
      "At iteration 1000 the loss is 0.422.\n",
      "At iteration 1500 the loss is 0.475.\n",
      "At iteration 2000 the loss is 0.424.\n",
      "At iteration 2500 the loss is 0.451.\n",
      "At iteration 3000 the loss is 0.435.\n",
      "At iteration 3500 the loss is 0.475.\n",
      "\n",
      "After epoch 32 the validation accuracy is 0.410.\n",
      "After epoch 32 the training accuracy is 0.770.\n",
      "\n",
      "At iteration 500 the loss is 0.501.\n",
      "At iteration 1000 the loss is 0.522.\n",
      "At iteration 1500 the loss is 0.447.\n",
      "At iteration 2000 the loss is 0.496.\n",
      "At iteration 2500 the loss is 0.382.\n",
      "At iteration 3000 the loss is 0.472.\n",
      "At iteration 3500 the loss is 0.485.\n",
      "\n",
      "After epoch 33 the validation accuracy is 0.424.\n",
      "After epoch 33 the training accuracy is 0.778.\n",
      "\n",
      "At iteration 500 the loss is 0.514.\n",
      "At iteration 1000 the loss is 0.411.\n",
      "At iteration 1500 the loss is 0.588.\n",
      "At iteration 2000 the loss is 0.480.\n",
      "At iteration 2500 the loss is 0.368.\n",
      "At iteration 3000 the loss is 0.490.\n",
      "At iteration 3500 the loss is 0.423.\n",
      "\n",
      "After epoch 34 the validation accuracy is 0.427.\n",
      "After epoch 34 the training accuracy is 0.781.\n",
      "\n",
      "At iteration 500 the loss is 0.407.\n",
      "At iteration 1000 the loss is 0.416.\n",
      "At iteration 1500 the loss is 0.471.\n",
      "At iteration 2000 the loss is 0.442.\n",
      "At iteration 2500 the loss is 0.409.\n",
      "At iteration 3000 the loss is 0.427.\n",
      "At iteration 3500 the loss is 0.409.\n",
      "\n",
      "After epoch 35 the validation accuracy is 0.421.\n",
      "After epoch 35 the training accuracy is 0.781.\n",
      "\n",
      "At iteration 500 the loss is 0.575.\n",
      "At iteration 1000 the loss is 0.377.\n",
      "At iteration 1500 the loss is 0.544.\n",
      "At iteration 2000 the loss is 0.563.\n",
      "At iteration 2500 the loss is 0.424.\n",
      "At iteration 3000 the loss is 0.429.\n",
      "At iteration 3500 the loss is 0.593.\n",
      "\n",
      "After epoch 36 the validation accuracy is 0.425.\n",
      "After epoch 36 the training accuracy is 0.784.\n",
      "\n",
      "At iteration 500 the loss is 0.414.\n",
      "At iteration 1000 the loss is 0.510.\n",
      "At iteration 1500 the loss is 0.480.\n",
      "At iteration 2000 the loss is 0.563.\n",
      "At iteration 2500 the loss is 0.410.\n",
      "At iteration 3000 the loss is 0.443.\n",
      "At iteration 3500 the loss is 0.365.\n",
      "\n",
      "After epoch 37 the validation accuracy is 0.422.\n",
      "After epoch 37 the training accuracy is 0.786.\n",
      "\n",
      "At iteration 500 the loss is 0.497.\n",
      "At iteration 1000 the loss is 0.422.\n",
      "At iteration 1500 the loss is 0.419.\n",
      "At iteration 2000 the loss is 0.439.\n",
      "At iteration 2500 the loss is 0.479.\n",
      "At iteration 3000 the loss is 0.535.\n",
      "At iteration 3500 the loss is 0.526.\n",
      "\n",
      "After epoch 38 the validation accuracy is 0.415.\n",
      "After epoch 38 the training accuracy is 0.782.\n",
      "\n",
      "At iteration 500 the loss is 0.394.\n",
      "At iteration 1000 the loss is 0.543.\n",
      "At iteration 1500 the loss is 0.519.\n",
      "At iteration 2000 the loss is 0.431.\n",
      "At iteration 2500 the loss is 0.545.\n",
      "At iteration 3000 the loss is 0.467.\n",
      "At iteration 3500 the loss is 0.399.\n",
      "\n",
      "After epoch 39 the validation accuracy is 0.422.\n",
      "After epoch 39 the training accuracy is 0.790.\n",
      "\n",
      "At iteration 500 the loss is 0.533.\n",
      "At iteration 1000 the loss is 0.314.\n",
      "At iteration 1500 the loss is 0.462.\n",
      "At iteration 2000 the loss is 0.560.\n",
      "At iteration 2500 the loss is 0.533.\n",
      "At iteration 3000 the loss is 0.447.\n",
      "At iteration 3500 the loss is 0.434.\n",
      "\n",
      "After epoch 40 the validation accuracy is 0.424.\n",
      "After epoch 40 the training accuracy is 0.792.\n",
      "\n",
      "At iteration 500 the loss is 0.384.\n",
      "At iteration 1000 the loss is 0.433.\n",
      "At iteration 1500 the loss is 0.539.\n",
      "At iteration 2000 the loss is 0.351.\n",
      "At iteration 2500 the loss is 0.527.\n",
      "At iteration 3000 the loss is 0.484.\n",
      "At iteration 3500 the loss is 0.581.\n",
      "\n",
      "After epoch 41 the validation accuracy is 0.421.\n",
      "After epoch 41 the training accuracy is 0.794.\n",
      "\n",
      "At iteration 500 the loss is 0.496.\n",
      "At iteration 1000 the loss is 0.436.\n",
      "At iteration 1500 the loss is 0.438.\n",
      "At iteration 2000 the loss is 0.409.\n",
      "At iteration 2500 the loss is 0.498.\n",
      "At iteration 3000 the loss is 0.377.\n",
      "At iteration 3500 the loss is 0.542.\n",
      "\n",
      "After epoch 42 the validation accuracy is 0.423.\n",
      "After epoch 42 the training accuracy is 0.794.\n",
      "\n",
      "At iteration 500 the loss is 0.562.\n",
      "At iteration 1000 the loss is 0.542.\n",
      "At iteration 1500 the loss is 0.492.\n",
      "At iteration 2000 the loss is 0.441.\n",
      "At iteration 2500 the loss is 0.462.\n",
      "At iteration 3000 the loss is 0.442.\n",
      "At iteration 3500 the loss is 0.492.\n",
      "\n",
      "After epoch 43 the validation accuracy is 0.425.\n",
      "After epoch 43 the training accuracy is 0.796.\n",
      "\n",
      "At iteration 500 the loss is 0.394.\n",
      "At iteration 1000 the loss is 0.487.\n",
      "At iteration 1500 the loss is 0.530.\n",
      "At iteration 2000 the loss is 0.413.\n",
      "At iteration 2500 the loss is 0.420.\n",
      "At iteration 3000 the loss is 0.452.\n",
      "At iteration 3500 the loss is 0.426.\n",
      "\n",
      "After epoch 44 the validation accuracy is 0.434.\n",
      "After epoch 44 the training accuracy is 0.799.\n",
      "\n",
      "At iteration 500 the loss is 0.428.\n",
      "At iteration 1000 the loss is 0.402.\n",
      "At iteration 1500 the loss is 0.456.\n",
      "At iteration 2000 the loss is 0.415.\n",
      "At iteration 2500 the loss is 0.444.\n",
      "At iteration 3000 the loss is 0.490.\n",
      "At iteration 3500 the loss is 0.411.\n",
      "\n",
      "After epoch 45 the validation accuracy is 0.430.\n",
      "After epoch 45 the training accuracy is 0.802.\n",
      "\n",
      "At iteration 500 the loss is 0.335.\n",
      "At iteration 1000 the loss is 0.494.\n",
      "At iteration 1500 the loss is 0.298.\n",
      "At iteration 2000 the loss is 0.432.\n",
      "At iteration 2500 the loss is 0.387.\n",
      "At iteration 3000 the loss is 0.480.\n",
      "At iteration 3500 the loss is 0.534.\n",
      "\n",
      "After epoch 46 the validation accuracy is 0.433.\n",
      "After epoch 46 the training accuracy is 0.804.\n",
      "\n",
      "At iteration 500 the loss is 0.462.\n",
      "At iteration 1000 the loss is 0.401.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 1500 the loss is 0.367.\n",
      "At iteration 2000 the loss is 0.381.\n",
      "At iteration 2500 the loss is 0.526.\n",
      "At iteration 3000 the loss is 0.458.\n",
      "At iteration 3500 the loss is 0.417.\n",
      "\n",
      "After epoch 47 the validation accuracy is 0.431.\n",
      "After epoch 47 the training accuracy is 0.805.\n",
      "\n",
      "At iteration 500 the loss is 0.465.\n",
      "At iteration 1000 the loss is 0.438.\n",
      "At iteration 1500 the loss is 0.457.\n",
      "At iteration 2000 the loss is 0.370.\n",
      "At iteration 2500 the loss is 0.449.\n",
      "At iteration 3000 the loss is 0.459.\n",
      "At iteration 3500 the loss is 0.491.\n",
      "\n",
      "After epoch 48 the validation accuracy is 0.424.\n",
      "After epoch 48 the training accuracy is 0.805.\n",
      "\n",
      "At iteration 500 the loss is 0.448.\n",
      "At iteration 1000 the loss is 0.424.\n",
      "At iteration 1500 the loss is 0.527.\n",
      "At iteration 2000 the loss is 0.375.\n",
      "At iteration 2500 the loss is 0.520.\n",
      "At iteration 3000 the loss is 0.341.\n",
      "At iteration 3500 the loss is 0.412.\n",
      "\n",
      "After epoch 49 the validation accuracy is 0.425.\n",
      "After epoch 49 the training accuracy is 0.807.\n",
      "\n",
      "At iteration 500 the loss is 0.357.\n",
      "At iteration 1000 the loss is 0.281.\n",
      "At iteration 1500 the loss is 0.452.\n",
      "At iteration 2000 the loss is 0.396.\n",
      "At iteration 2500 the loss is 0.413.\n",
      "At iteration 3000 the loss is 0.416.\n",
      "At iteration 3500 the loss is 0.483.\n",
      "\n",
      "After epoch 50 the validation accuracy is 0.431.\n",
      "After epoch 50 the training accuracy is 0.809.\n",
      "\n",
      "At iteration 500 the loss is 0.444.\n",
      "At iteration 1000 the loss is 0.404.\n",
      "At iteration 1500 the loss is 0.417.\n",
      "At iteration 2000 the loss is 0.456.\n",
      "At iteration 2500 the loss is 0.371.\n",
      "At iteration 3000 the loss is 0.442.\n",
      "At iteration 3500 the loss is 0.394.\n",
      "\n",
      "After epoch 51 the validation accuracy is 0.425.\n",
      "After epoch 51 the training accuracy is 0.810.\n",
      "\n",
      "At iteration 500 the loss is 0.406.\n",
      "At iteration 1000 the loss is 0.449.\n",
      "At iteration 1500 the loss is 0.355.\n",
      "At iteration 2000 the loss is 0.588.\n",
      "At iteration 2500 the loss is 0.334.\n",
      "At iteration 3000 the loss is 0.384.\n",
      "At iteration 3500 the loss is 0.467.\n",
      "\n",
      "After epoch 52 the validation accuracy is 0.437.\n",
      "After epoch 52 the training accuracy is 0.815.\n",
      "\n",
      "At iteration 500 the loss is 0.447.\n",
      "At iteration 1000 the loss is 0.384.\n",
      "At iteration 1500 the loss is 0.451.\n",
      "At iteration 2000 the loss is 0.317.\n",
      "At iteration 2500 the loss is 0.373.\n",
      "At iteration 3000 the loss is 0.460.\n",
      "At iteration 3500 the loss is 0.366.\n",
      "\n",
      "After epoch 53 the validation accuracy is 0.442.\n",
      "After epoch 53 the training accuracy is 0.813.\n",
      "\n",
      "At iteration 500 the loss is 0.387.\n",
      "At iteration 1000 the loss is 0.380.\n",
      "At iteration 1500 the loss is 0.366.\n",
      "At iteration 2000 the loss is 0.436.\n",
      "At iteration 2500 the loss is 0.327.\n",
      "At iteration 3000 the loss is 0.473.\n",
      "At iteration 3500 the loss is 0.373.\n",
      "\n",
      "After epoch 54 the validation accuracy is 0.434.\n",
      "After epoch 54 the training accuracy is 0.814.\n",
      "\n",
      "At iteration 500 the loss is 0.390.\n",
      "At iteration 1000 the loss is 0.436.\n",
      "At iteration 1500 the loss is 0.314.\n",
      "At iteration 2000 the loss is 0.449.\n",
      "At iteration 2500 the loss is 0.417.\n",
      "At iteration 3000 the loss is 0.357.\n",
      "At iteration 3500 the loss is 0.311.\n",
      "\n",
      "After epoch 55 the validation accuracy is 0.433.\n",
      "After epoch 55 the training accuracy is 0.818.\n",
      "\n",
      "At iteration 500 the loss is 0.446.\n",
      "At iteration 1000 the loss is 0.311.\n",
      "At iteration 1500 the loss is 0.359.\n",
      "At iteration 2000 the loss is 0.545.\n",
      "At iteration 2500 the loss is 0.351.\n",
      "At iteration 3000 the loss is 0.526.\n",
      "At iteration 3500 the loss is 0.358.\n",
      "\n",
      "After epoch 56 the validation accuracy is 0.429.\n",
      "After epoch 56 the training accuracy is 0.819.\n",
      "\n",
      "At iteration 500 the loss is 0.427.\n",
      "At iteration 1000 the loss is 0.431.\n",
      "At iteration 1500 the loss is 0.438.\n",
      "At iteration 2000 the loss is 0.459.\n",
      "At iteration 2500 the loss is 0.486.\n",
      "At iteration 3000 the loss is 0.379.\n",
      "At iteration 3500 the loss is 0.346.\n",
      "\n",
      "After epoch 57 the validation accuracy is 0.429.\n",
      "After epoch 57 the training accuracy is 0.821.\n",
      "\n",
      "At iteration 500 the loss is 0.335.\n",
      "At iteration 1000 the loss is 0.305.\n",
      "At iteration 1500 the loss is 0.493.\n",
      "At iteration 2000 the loss is 0.430.\n",
      "At iteration 2500 the loss is 0.387.\n",
      "At iteration 3000 the loss is 0.530.\n",
      "At iteration 3500 the loss is 0.462.\n",
      "\n",
      "After epoch 58 the validation accuracy is 0.441.\n",
      "After epoch 58 the training accuracy is 0.820.\n",
      "\n",
      "At iteration 500 the loss is 0.432.\n",
      "At iteration 1000 the loss is 0.376.\n",
      "At iteration 1500 the loss is 0.427.\n",
      "At iteration 2000 the loss is 0.455.\n",
      "At iteration 2500 the loss is 0.402.\n",
      "At iteration 3000 the loss is 0.427.\n",
      "At iteration 3500 the loss is 0.375.\n",
      "\n",
      "After epoch 59 the validation accuracy is 0.438.\n",
      "After epoch 59 the training accuracy is 0.819.\n",
      "\n",
      "At iteration 500 the loss is 0.437.\n",
      "At iteration 1000 the loss is 0.398.\n",
      "At iteration 1500 the loss is 0.463.\n",
      "At iteration 2000 the loss is 0.408.\n",
      "At iteration 2500 the loss is 0.438.\n",
      "At iteration 3000 the loss is 0.320.\n",
      "At iteration 3500 the loss is 0.386.\n",
      "\n",
      "After epoch 60 the validation accuracy is 0.431.\n",
      "After epoch 60 the training accuracy is 0.823.\n",
      "\n",
      "At iteration 500 the loss is 0.437.\n",
      "At iteration 1000 the loss is 0.300.\n",
      "At iteration 1500 the loss is 0.309.\n",
      "At iteration 2000 the loss is 0.454.\n",
      "At iteration 2500 the loss is 0.378.\n",
      "At iteration 3000 the loss is 0.314.\n",
      "At iteration 3500 the loss is 0.245.\n",
      "\n",
      "After epoch 61 the validation accuracy is 0.434.\n",
      "After epoch 61 the training accuracy is 0.825.\n",
      "\n",
      "At iteration 500 the loss is 0.373.\n",
      "At iteration 1000 the loss is 0.356.\n",
      "At iteration 1500 the loss is 0.399.\n",
      "At iteration 2000 the loss is 0.320.\n",
      "At iteration 2500 the loss is 0.310.\n",
      "At iteration 3000 the loss is 0.393.\n",
      "At iteration 3500 the loss is 0.440.\n",
      "\n",
      "After epoch 62 the validation accuracy is 0.432.\n",
      "After epoch 62 the training accuracy is 0.826.\n",
      "\n",
      "At iteration 500 the loss is 0.391.\n",
      "At iteration 1000 the loss is 0.378.\n",
      "At iteration 1500 the loss is 0.371.\n",
      "At iteration 2000 the loss is 0.383.\n",
      "At iteration 2500 the loss is 0.329.\n",
      "At iteration 3000 the loss is 0.375.\n",
      "At iteration 3500 the loss is 0.360.\n",
      "\n",
      "After epoch 63 the validation accuracy is 0.428.\n",
      "After epoch 63 the training accuracy is 0.826.\n",
      "\n",
      "At iteration 500 the loss is 0.300.\n",
      "At iteration 1000 the loss is 0.314.\n",
      "At iteration 1500 the loss is 0.426.\n",
      "At iteration 2000 the loss is 0.329.\n",
      "At iteration 2500 the loss is 0.347.\n",
      "At iteration 3000 the loss is 0.331.\n",
      "At iteration 3500 the loss is 0.406.\n",
      "\n",
      "After epoch 64 the validation accuracy is 0.433.\n",
      "After epoch 64 the training accuracy is 0.827.\n",
      "\n",
      "At iteration 500 the loss is 0.359.\n",
      "At iteration 1000 the loss is 0.362.\n",
      "At iteration 1500 the loss is 0.415.\n",
      "At iteration 2000 the loss is 0.374.\n",
      "At iteration 2500 the loss is 0.428.\n",
      "At iteration 3000 the loss is 0.419.\n",
      "At iteration 3500 the loss is 0.361.\n",
      "\n",
      "After epoch 65 the validation accuracy is 0.430.\n",
      "After epoch 65 the training accuracy is 0.831.\n",
      "\n",
      "At iteration 500 the loss is 0.450.\n",
      "At iteration 1000 the loss is 0.314.\n",
      "At iteration 1500 the loss is 0.351.\n",
      "At iteration 2000 the loss is 0.375.\n",
      "At iteration 2500 the loss is 0.368.\n",
      "At iteration 3000 the loss is 0.447.\n",
      "At iteration 3500 the loss is 0.372.\n",
      "\n",
      "After epoch 66 the validation accuracy is 0.429.\n",
      "After epoch 66 the training accuracy is 0.831.\n",
      "\n",
      "At iteration 500 the loss is 0.344.\n",
      "At iteration 1000 the loss is 0.422.\n",
      "At iteration 1500 the loss is 0.333.\n",
      "At iteration 2000 the loss is 0.319.\n",
      "At iteration 2500 the loss is 0.365.\n",
      "At iteration 3000 the loss is 0.363.\n",
      "At iteration 3500 the loss is 0.407.\n",
      "\n",
      "After epoch 67 the validation accuracy is 0.419.\n",
      "After epoch 67 the training accuracy is 0.823.\n",
      "\n",
      "At iteration 500 the loss is 0.291.\n",
      "At iteration 1000 the loss is 0.381.\n",
      "At iteration 1500 the loss is 0.367.\n",
      "At iteration 2000 the loss is 0.353.\n",
      "At iteration 2500 the loss is 0.378.\n",
      "At iteration 3000 the loss is 0.418.\n",
      "At iteration 3500 the loss is 0.387.\n",
      "\n",
      "After epoch 68 the validation accuracy is 0.430.\n",
      "After epoch 68 the training accuracy is 0.833.\n",
      "\n",
      "At iteration 500 the loss is 0.360.\n",
      "At iteration 1000 the loss is 0.405.\n",
      "At iteration 1500 the loss is 0.283.\n",
      "At iteration 2000 the loss is 0.446.\n",
      "At iteration 2500 the loss is 0.428.\n",
      "At iteration 3000 the loss is 0.385.\n",
      "At iteration 3500 the loss is 0.388.\n",
      "\n",
      "After epoch 69 the validation accuracy is 0.429.\n",
      "After epoch 69 the training accuracy is 0.833.\n",
      "\n",
      "At iteration 500 the loss is 0.398.\n",
      "At iteration 1000 the loss is 0.370.\n",
      "At iteration 1500 the loss is 0.513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 2000 the loss is 0.381.\n",
      "At iteration 2500 the loss is 0.353.\n",
      "At iteration 3000 the loss is 0.383.\n",
      "At iteration 3500 the loss is 0.306.\n",
      "\n",
      "After epoch 70 the validation accuracy is 0.432.\n",
      "After epoch 70 the training accuracy is 0.836.\n",
      "\n",
      "At iteration 500 the loss is 0.391.\n",
      "At iteration 1000 the loss is 0.327.\n",
      "At iteration 1500 the loss is 0.424.\n",
      "At iteration 2000 the loss is 0.326.\n",
      "At iteration 2500 the loss is 0.276.\n",
      "At iteration 3000 the loss is 0.287.\n",
      "At iteration 3500 the loss is 0.435.\n",
      "\n",
      "After epoch 71 the validation accuracy is 0.434.\n",
      "After epoch 71 the training accuracy is 0.834.\n",
      "\n",
      "At iteration 500 the loss is 0.344.\n",
      "At iteration 1000 the loss is 0.336.\n",
      "At iteration 1500 the loss is 0.360.\n",
      "At iteration 2000 the loss is 0.324.\n",
      "At iteration 2500 the loss is 0.383.\n",
      "At iteration 3000 the loss is 0.308.\n",
      "At iteration 3500 the loss is 0.358.\n",
      "\n",
      "After epoch 72 the validation accuracy is 0.438.\n",
      "After epoch 72 the training accuracy is 0.839.\n",
      "\n",
      "At iteration 500 the loss is 0.406.\n",
      "At iteration 1000 the loss is 0.332.\n",
      "At iteration 1500 the loss is 0.396.\n",
      "At iteration 2000 the loss is 0.356.\n",
      "At iteration 2500 the loss is 0.428.\n",
      "At iteration 3000 the loss is 0.288.\n",
      "At iteration 3500 the loss is 0.391.\n",
      "\n",
      "After epoch 73 the validation accuracy is 0.440.\n",
      "After epoch 73 the training accuracy is 0.837.\n",
      "\n",
      "At iteration 500 the loss is 0.281.\n",
      "At iteration 1000 the loss is 0.417.\n",
      "At iteration 1500 the loss is 0.273.\n",
      "At iteration 2000 the loss is 0.422.\n",
      "At iteration 2500 the loss is 0.291.\n",
      "At iteration 3000 the loss is 0.420.\n",
      "At iteration 3500 the loss is 0.468.\n",
      "\n",
      "After epoch 74 the validation accuracy is 0.436.\n",
      "After epoch 74 the training accuracy is 0.842.\n",
      "\n",
      "At iteration 500 the loss is 0.340.\n",
      "At iteration 1000 the loss is 0.362.\n",
      "At iteration 1500 the loss is 0.499.\n",
      "At iteration 2000 the loss is 0.372.\n",
      "At iteration 2500 the loss is 0.342.\n",
      "At iteration 3000 the loss is 0.339.\n",
      "At iteration 3500 the loss is 0.314.\n",
      "\n",
      "After epoch 75 the validation accuracy is 0.428.\n",
      "After epoch 75 the training accuracy is 0.840.\n",
      "\n",
      "At iteration 500 the loss is 0.374.\n",
      "At iteration 1000 the loss is 0.292.\n",
      "At iteration 1500 the loss is 0.272.\n",
      "At iteration 2000 the loss is 0.474.\n",
      "At iteration 2500 the loss is 0.461.\n",
      "At iteration 3000 the loss is 0.310.\n",
      "At iteration 3500 the loss is 0.317.\n",
      "\n",
      "After epoch 76 the validation accuracy is 0.439.\n",
      "After epoch 76 the training accuracy is 0.843.\n",
      "\n",
      "At iteration 500 the loss is 0.290.\n",
      "At iteration 1000 the loss is 0.380.\n",
      "At iteration 1500 the loss is 0.423.\n",
      "At iteration 2000 the loss is 0.372.\n",
      "At iteration 2500 the loss is 0.440.\n",
      "At iteration 3000 the loss is 0.404.\n",
      "At iteration 3500 the loss is 0.294.\n",
      "\n",
      "After epoch 77 the validation accuracy is 0.431.\n",
      "After epoch 77 the training accuracy is 0.843.\n",
      "\n",
      "At iteration 500 the loss is 0.460.\n",
      "At iteration 1000 the loss is 0.420.\n",
      "At iteration 1500 the loss is 0.350.\n",
      "At iteration 2000 the loss is 0.385.\n",
      "At iteration 2500 the loss is 0.392.\n",
      "At iteration 3000 the loss is 0.365.\n",
      "At iteration 3500 the loss is 0.411.\n",
      "\n",
      "After epoch 78 the validation accuracy is 0.438.\n",
      "After epoch 78 the training accuracy is 0.844.\n",
      "\n",
      "At iteration 500 the loss is 0.358.\n",
      "At iteration 1000 the loss is 0.349.\n",
      "At iteration 1500 the loss is 0.379.\n",
      "At iteration 2000 the loss is 0.394.\n",
      "At iteration 2500 the loss is 0.415.\n",
      "At iteration 3000 the loss is 0.414.\n",
      "At iteration 3500 the loss is 0.256.\n",
      "\n",
      "After epoch 79 the validation accuracy is 0.434.\n",
      "After epoch 79 the training accuracy is 0.840.\n",
      "\n",
      "At iteration 500 the loss is 0.350.\n",
      "At iteration 1000 the loss is 0.318.\n",
      "At iteration 1500 the loss is 0.303.\n",
      "At iteration 2000 the loss is 0.457.\n",
      "At iteration 2500 the loss is 0.374.\n",
      "At iteration 3000 the loss is 0.471.\n",
      "At iteration 3500 the loss is 0.346.\n",
      "\n",
      "After epoch 80 the validation accuracy is 0.439.\n",
      "After epoch 80 the training accuracy is 0.846.\n",
      "\n",
      "At iteration 500 the loss is 0.412.\n",
      "At iteration 1000 the loss is 0.441.\n",
      "At iteration 1500 the loss is 0.384.\n",
      "At iteration 2000 the loss is 0.355.\n",
      "At iteration 2500 the loss is 0.434.\n",
      "At iteration 3000 the loss is 0.217.\n",
      "At iteration 3500 the loss is 0.228.\n",
      "\n",
      "After epoch 81 the validation accuracy is 0.437.\n",
      "After epoch 81 the training accuracy is 0.848.\n",
      "\n",
      "At iteration 500 the loss is 0.348.\n",
      "At iteration 1000 the loss is 0.338.\n",
      "At iteration 1500 the loss is 0.273.\n",
      "At iteration 2000 the loss is 0.474.\n",
      "At iteration 2500 the loss is 0.287.\n",
      "At iteration 3000 the loss is 0.306.\n",
      "At iteration 3500 the loss is 0.332.\n",
      "\n",
      "After epoch 82 the validation accuracy is 0.435.\n",
      "After epoch 82 the training accuracy is 0.849.\n",
      "\n",
      "At iteration 500 the loss is 0.381.\n",
      "At iteration 1000 the loss is 0.375.\n",
      "At iteration 1500 the loss is 0.397.\n",
      "At iteration 2000 the loss is 0.355.\n",
      "At iteration 2500 the loss is 0.360.\n",
      "At iteration 3000 the loss is 0.358.\n",
      "At iteration 3500 the loss is 0.496.\n",
      "\n",
      "After epoch 83 the validation accuracy is 0.443.\n",
      "After epoch 83 the training accuracy is 0.848.\n",
      "\n",
      "At iteration 500 the loss is 0.317.\n",
      "At iteration 1000 the loss is 0.370.\n",
      "At iteration 1500 the loss is 0.330.\n",
      "At iteration 2000 the loss is 0.336.\n",
      "At iteration 2500 the loss is 0.365.\n",
      "At iteration 3000 the loss is 0.350.\n",
      "At iteration 3500 the loss is 0.373.\n",
      "\n",
      "After epoch 84 the validation accuracy is 0.438.\n",
      "After epoch 84 the training accuracy is 0.847.\n",
      "\n",
      "At iteration 500 the loss is 0.281.\n",
      "At iteration 1000 the loss is 0.276.\n",
      "At iteration 1500 the loss is 0.322.\n",
      "At iteration 2000 the loss is 0.401.\n",
      "At iteration 2500 the loss is 0.344.\n",
      "At iteration 3000 the loss is 0.337.\n",
      "At iteration 3500 the loss is 0.363.\n",
      "\n",
      "After epoch 85 the validation accuracy is 0.433.\n",
      "After epoch 85 the training accuracy is 0.850.\n",
      "\n",
      "At iteration 500 the loss is 0.273.\n",
      "At iteration 1000 the loss is 0.338.\n",
      "At iteration 1500 the loss is 0.378.\n",
      "At iteration 2000 the loss is 0.416.\n",
      "At iteration 2500 the loss is 0.354.\n",
      "At iteration 3000 the loss is 0.376.\n",
      "At iteration 3500 the loss is 0.318.\n",
      "\n",
      "After epoch 86 the validation accuracy is 0.440.\n",
      "After epoch 86 the training accuracy is 0.852.\n",
      "\n",
      "At iteration 500 the loss is 0.318.\n",
      "At iteration 1000 the loss is 0.296.\n",
      "At iteration 1500 the loss is 0.354.\n",
      "At iteration 2000 the loss is 0.336.\n",
      "At iteration 2500 the loss is 0.308.\n",
      "At iteration 3000 the loss is 0.389.\n",
      "At iteration 3500 the loss is 0.339.\n",
      "\n",
      "After epoch 87 the validation accuracy is 0.440.\n",
      "After epoch 87 the training accuracy is 0.851.\n",
      "\n",
      "At iteration 500 the loss is 0.313.\n",
      "At iteration 1000 the loss is 0.334.\n",
      "At iteration 1500 the loss is 0.313.\n",
      "At iteration 2000 the loss is 0.279.\n",
      "At iteration 2500 the loss is 0.411.\n",
      "At iteration 3000 the loss is 0.381.\n",
      "At iteration 3500 the loss is 0.396.\n",
      "\n",
      "After epoch 88 the validation accuracy is 0.430.\n",
      "After epoch 88 the training accuracy is 0.845.\n",
      "\n",
      "At iteration 500 the loss is 0.255.\n",
      "At iteration 1000 the loss is 0.377.\n",
      "At iteration 1500 the loss is 0.422.\n",
      "At iteration 2000 the loss is 0.298.\n",
      "At iteration 2500 the loss is 0.202.\n",
      "At iteration 3000 the loss is 0.380.\n",
      "At iteration 3500 the loss is 0.460.\n",
      "\n",
      "After epoch 89 the validation accuracy is 0.438.\n",
      "After epoch 89 the training accuracy is 0.855.\n",
      "\n",
      "At iteration 500 the loss is 0.406.\n",
      "At iteration 1000 the loss is 0.369.\n",
      "At iteration 1500 the loss is 0.315.\n",
      "At iteration 2000 the loss is 0.289.\n",
      "At iteration 2500 the loss is 0.322.\n",
      "At iteration 3000 the loss is 0.360.\n",
      "At iteration 3500 the loss is 0.318.\n",
      "\n",
      "After epoch 90 the validation accuracy is 0.445.\n",
      "After epoch 90 the training accuracy is 0.854.\n",
      "\n",
      "At iteration 500 the loss is 0.258.\n",
      "At iteration 1000 the loss is 0.344.\n",
      "At iteration 1500 the loss is 0.336.\n",
      "At iteration 2000 the loss is 0.405.\n",
      "At iteration 2500 the loss is 0.364.\n",
      "At iteration 3000 the loss is 0.353.\n",
      "At iteration 3500 the loss is 0.470.\n",
      "\n",
      "After epoch 91 the validation accuracy is 0.444.\n",
      "After epoch 91 the training accuracy is 0.855.\n",
      "\n",
      "At iteration 500 the loss is 0.285.\n",
      "At iteration 1000 the loss is 0.372.\n",
      "At iteration 1500 the loss is 0.401.\n",
      "At iteration 2000 the loss is 0.291.\n",
      "At iteration 2500 the loss is 0.416.\n",
      "At iteration 3000 the loss is 0.215.\n",
      "At iteration 3500 the loss is 0.296.\n",
      "\n",
      "After epoch 92 the validation accuracy is 0.439.\n",
      "After epoch 92 the training accuracy is 0.856.\n",
      "\n",
      "At iteration 500 the loss is 0.359.\n",
      "At iteration 1000 the loss is 0.313.\n",
      "At iteration 1500 the loss is 0.281.\n",
      "At iteration 2000 the loss is 0.380.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 2500 the loss is 0.345.\n",
      "At iteration 3000 the loss is 0.440.\n",
      "At iteration 3500 the loss is 0.339.\n",
      "\n",
      "After epoch 93 the validation accuracy is 0.445.\n",
      "After epoch 93 the training accuracy is 0.857.\n",
      "\n",
      "At iteration 500 the loss is 0.274.\n",
      "At iteration 1000 the loss is 0.318.\n",
      "At iteration 1500 the loss is 0.326.\n",
      "At iteration 2000 the loss is 0.294.\n",
      "At iteration 2500 the loss is 0.365.\n",
      "At iteration 3000 the loss is 0.257.\n",
      "At iteration 3500 the loss is 0.421.\n",
      "\n",
      "After epoch 94 the validation accuracy is 0.438.\n",
      "After epoch 94 the training accuracy is 0.858.\n",
      "\n",
      "At iteration 500 the loss is 0.261.\n",
      "At iteration 1000 the loss is 0.330.\n",
      "At iteration 1500 the loss is 0.262.\n",
      "At iteration 2000 the loss is 0.431.\n",
      "At iteration 2500 the loss is 0.334.\n",
      "At iteration 3000 the loss is 0.385.\n",
      "At iteration 3500 the loss is 0.257.\n",
      "\n",
      "After epoch 95 the validation accuracy is 0.435.\n",
      "After epoch 95 the training accuracy is 0.857.\n",
      "\n",
      "At iteration 500 the loss is 0.241.\n",
      "At iteration 1000 the loss is 0.368.\n",
      "At iteration 1500 the loss is 0.295.\n",
      "At iteration 2000 the loss is 0.302.\n",
      "At iteration 2500 the loss is 0.269.\n",
      "At iteration 3000 the loss is 0.275.\n",
      "At iteration 3500 the loss is 0.317.\n",
      "\n",
      "After epoch 96 the validation accuracy is 0.434.\n",
      "After epoch 96 the training accuracy is 0.857.\n",
      "\n",
      "At iteration 500 the loss is 0.271.\n",
      "At iteration 1000 the loss is 0.215.\n",
      "At iteration 1500 the loss is 0.369.\n",
      "At iteration 2000 the loss is 0.307.\n",
      "At iteration 2500 the loss is 0.279.\n",
      "At iteration 3000 the loss is 0.324.\n",
      "At iteration 3500 the loss is 0.322.\n",
      "\n",
      "After epoch 97 the validation accuracy is 0.440.\n",
      "After epoch 97 the training accuracy is 0.859.\n",
      "\n",
      "At iteration 500 the loss is 0.253.\n",
      "At iteration 1000 the loss is 0.387.\n",
      "At iteration 1500 the loss is 0.386.\n",
      "At iteration 2000 the loss is 0.362.\n",
      "At iteration 2500 the loss is 0.347.\n",
      "At iteration 3000 the loss is 0.248.\n",
      "At iteration 3500 the loss is 0.280.\n",
      "\n",
      "After epoch 98 the validation accuracy is 0.435.\n",
      "After epoch 98 the training accuracy is 0.857.\n",
      "\n",
      "At iteration 500 the loss is 0.395.\n",
      "At iteration 1000 the loss is 0.392.\n",
      "At iteration 1500 the loss is 0.297.\n",
      "At iteration 2000 the loss is 0.362.\n",
      "At iteration 2500 the loss is 0.314.\n",
      "At iteration 3000 the loss is 0.443.\n",
      "At iteration 3500 the loss is 0.294.\n",
      "\n",
      "After epoch 99 the validation accuracy is 0.440.\n",
      "After epoch 99 the training accuracy is 0.861.\n",
      "\n",
      "At iteration 500 the loss is 0.365.\n",
      "At iteration 1000 the loss is 0.400.\n",
      "At iteration 1500 the loss is 0.311.\n",
      "At iteration 2000 the loss is 0.333.\n",
      "At iteration 2500 the loss is 0.420.\n",
      "At iteration 3000 the loss is 0.274.\n",
      "At iteration 3500 the loss is 0.440.\n",
      "\n",
      "After epoch 100 the validation accuracy is 0.440.\n",
      "After epoch 100 the training accuracy is 0.862.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100 # epoch\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "accuracies=[]\n",
    "train_accuracies=[]\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train_an_epoch(train_dataloader)\n",
    "    accuracy = get_accuracy(valid_dataloader)\n",
    "    train_accuracy = get_accuracy(train_dataloader)\n",
    "    accuracies.append(accuracy)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    time_taken = time.time() - epoch_start_time\n",
    "    print()\n",
    "    print(f'After epoch {epoch} the validation accuracy is {accuracy:.3f}.')\n",
    "    print(f'After epoch {epoch} the training accuracy is {train_accuracy:.3f}.')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6f39c013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x18d8f1e7908>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracies, label=\"Validation Accuracy\")\n",
    "plt.plot(train_accuracies, label=\"Training Accuracy\")\n",
    "plt.xlabel(\"Training Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "06617fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, \n",
    "                              collate_fn=collate_into_cbow)\n",
    "valid_dataloader = DataLoader(valid_iter, batch_size=BATCH_SIZE,\n",
    "                              shuffle=False, \n",
    "                              collate_fn=collate_into_cbow)\n",
    "\n",
    "model = LogRegClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "15811286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 500 the loss is 0.615.\n",
      "At iteration 1000 the loss is 0.759.\n",
      "At iteration 1500 the loss is 0.648.\n",
      "At iteration 2000 the loss is 0.663.\n",
      "At iteration 2500 the loss is 0.644.\n",
      "At iteration 3000 the loss is 0.625.\n",
      "At iteration 3500 the loss is 0.651.\n",
      "\n",
      "After epoch 1 the validation accuracy is 0.368.\n",
      "After epoch 1 the training accuracy is 0.670.\n",
      "\n",
      "At iteration 500 the loss is 0.641.\n",
      "At iteration 1000 the loss is 0.678.\n",
      "At iteration 1500 the loss is 0.720.\n",
      "At iteration 2000 the loss is 0.677.\n",
      "At iteration 2500 the loss is 0.552.\n",
      "At iteration 3000 the loss is 0.725.\n",
      "At iteration 3500 the loss is 0.627.\n",
      "\n",
      "After epoch 2 the validation accuracy is 0.367.\n",
      "After epoch 2 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.630.\n",
      "At iteration 1000 the loss is 0.588.\n",
      "At iteration 1500 the loss is 0.617.\n",
      "At iteration 2000 the loss is 0.629.\n",
      "At iteration 2500 the loss is 0.680.\n",
      "At iteration 3000 the loss is 0.616.\n",
      "At iteration 3500 the loss is 0.641.\n",
      "\n",
      "After epoch 3 the validation accuracy is 0.367.\n",
      "After epoch 3 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.582.\n",
      "At iteration 1000 the loss is 0.541.\n",
      "At iteration 1500 the loss is 0.627.\n",
      "At iteration 2000 the loss is 0.581.\n",
      "At iteration 2500 the loss is 0.686.\n",
      "At iteration 3000 the loss is 0.634.\n",
      "At iteration 3500 the loss is 0.615.\n",
      "\n",
      "After epoch 4 the validation accuracy is 0.367.\n",
      "After epoch 4 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.614.\n",
      "At iteration 1000 the loss is 0.654.\n",
      "At iteration 1500 the loss is 0.629.\n",
      "At iteration 2000 the loss is 0.653.\n",
      "At iteration 2500 the loss is 0.588.\n",
      "At iteration 3000 the loss is 0.572.\n",
      "At iteration 3500 the loss is 0.635.\n",
      "\n",
      "After epoch 5 the validation accuracy is 0.367.\n",
      "After epoch 5 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.564.\n",
      "At iteration 1000 the loss is 0.662.\n",
      "At iteration 1500 the loss is 0.612.\n",
      "At iteration 2000 the loss is 0.645.\n",
      "At iteration 2500 the loss is 0.630.\n",
      "At iteration 3000 the loss is 0.651.\n",
      "At iteration 3500 the loss is 0.658.\n",
      "\n",
      "After epoch 6 the validation accuracy is 0.367.\n",
      "After epoch 6 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.618.\n",
      "At iteration 1000 the loss is 0.597.\n",
      "At iteration 1500 the loss is 0.606.\n",
      "At iteration 2000 the loss is 0.565.\n",
      "At iteration 2500 the loss is 0.595.\n",
      "At iteration 3000 the loss is 0.636.\n",
      "At iteration 3500 the loss is 0.526.\n",
      "\n",
      "After epoch 7 the validation accuracy is 0.367.\n",
      "After epoch 7 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.599.\n",
      "At iteration 1000 the loss is 0.627.\n",
      "At iteration 1500 the loss is 0.667.\n",
      "At iteration 2000 the loss is 0.657.\n",
      "At iteration 2500 the loss is 0.633.\n",
      "At iteration 3000 the loss is 0.668.\n",
      "At iteration 3500 the loss is 0.577.\n",
      "\n",
      "After epoch 8 the validation accuracy is 0.367.\n",
      "After epoch 8 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.607.\n",
      "At iteration 1000 the loss is 0.637.\n",
      "At iteration 1500 the loss is 0.582.\n",
      "At iteration 2000 the loss is 0.604.\n",
      "At iteration 2500 the loss is 0.604.\n",
      "At iteration 3000 the loss is 0.561.\n",
      "At iteration 3500 the loss is 0.606.\n",
      "\n",
      "After epoch 9 the validation accuracy is 0.367.\n",
      "After epoch 9 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.697.\n",
      "At iteration 1000 the loss is 0.653.\n",
      "At iteration 1500 the loss is 0.586.\n",
      "At iteration 2000 the loss is 0.694.\n",
      "At iteration 2500 the loss is 0.602.\n",
      "At iteration 3000 the loss is 0.666.\n",
      "At iteration 3500 the loss is 0.589.\n",
      "\n",
      "After epoch 10 the validation accuracy is 0.367.\n",
      "After epoch 10 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.660.\n",
      "At iteration 1000 the loss is 0.646.\n",
      "At iteration 1500 the loss is 0.630.\n",
      "At iteration 2000 the loss is 0.601.\n",
      "At iteration 2500 the loss is 0.602.\n",
      "At iteration 3000 the loss is 0.688.\n",
      "At iteration 3500 the loss is 0.673.\n",
      "\n",
      "After epoch 11 the validation accuracy is 0.367.\n",
      "After epoch 11 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.648.\n",
      "At iteration 1000 the loss is 0.578.\n",
      "At iteration 1500 the loss is 0.553.\n",
      "At iteration 2000 the loss is 0.626.\n",
      "At iteration 2500 the loss is 0.610.\n",
      "At iteration 3000 the loss is 0.624.\n",
      "At iteration 3500 the loss is 0.631.\n",
      "\n",
      "After epoch 12 the validation accuracy is 0.367.\n",
      "After epoch 12 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.570.\n",
      "At iteration 1000 the loss is 0.630.\n",
      "At iteration 1500 the loss is 0.540.\n",
      "At iteration 2000 the loss is 0.548.\n",
      "At iteration 2500 the loss is 0.698.\n",
      "At iteration 3000 the loss is 0.576.\n",
      "At iteration 3500 the loss is 0.665.\n",
      "\n",
      "After epoch 13 the validation accuracy is 0.367.\n",
      "After epoch 13 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.648.\n",
      "At iteration 1000 the loss is 0.629.\n",
      "At iteration 1500 the loss is 0.605.\n",
      "At iteration 2000 the loss is 0.617.\n",
      "At iteration 2500 the loss is 0.723.\n",
      "At iteration 3000 the loss is 0.585.\n",
      "At iteration 3500 the loss is 0.630.\n",
      "\n",
      "After epoch 14 the validation accuracy is 0.367.\n",
      "After epoch 14 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.613.\n",
      "At iteration 1000 the loss is 0.642.\n",
      "At iteration 1500 the loss is 0.596.\n",
      "At iteration 2000 the loss is 0.614.\n",
      "At iteration 2500 the loss is 0.668.\n",
      "At iteration 3000 the loss is 0.605.\n",
      "At iteration 3500 the loss is 0.545.\n",
      "\n",
      "After epoch 15 the validation accuracy is 0.367.\n",
      "After epoch 15 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.576.\n",
      "At iteration 1000 the loss is 0.612.\n",
      "At iteration 1500 the loss is 0.583.\n",
      "At iteration 2000 the loss is 0.617.\n",
      "At iteration 2500 the loss is 0.588.\n",
      "At iteration 3000 the loss is 0.663.\n",
      "At iteration 3500 the loss is 0.608.\n",
      "\n",
      "After epoch 16 the validation accuracy is 0.367.\n",
      "After epoch 16 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.664.\n",
      "At iteration 1000 the loss is 0.632.\n",
      "At iteration 1500 the loss is 0.573.\n",
      "At iteration 2000 the loss is 0.574.\n",
      "At iteration 2500 the loss is 0.662.\n",
      "At iteration 3000 the loss is 0.638.\n",
      "At iteration 3500 the loss is 0.607.\n",
      "\n",
      "After epoch 17 the validation accuracy is 0.367.\n",
      "After epoch 17 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.717.\n",
      "At iteration 1000 the loss is 0.656.\n",
      "At iteration 1500 the loss is 0.588.\n",
      "At iteration 2000 the loss is 0.519.\n",
      "At iteration 2500 the loss is 0.669.\n",
      "At iteration 3000 the loss is 0.638.\n",
      "At iteration 3500 the loss is 0.580.\n",
      "\n",
      "After epoch 18 the validation accuracy is 0.367.\n",
      "After epoch 18 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.598.\n",
      "At iteration 1000 the loss is 0.614.\n",
      "At iteration 1500 the loss is 0.586.\n",
      "At iteration 2000 the loss is 0.633.\n",
      "At iteration 2500 the loss is 0.668.\n",
      "At iteration 3000 the loss is 0.625.\n",
      "At iteration 3500 the loss is 0.663.\n",
      "\n",
      "After epoch 19 the validation accuracy is 0.367.\n",
      "After epoch 19 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.593.\n",
      "At iteration 1000 the loss is 0.645.\n",
      "At iteration 1500 the loss is 0.645.\n",
      "At iteration 2000 the loss is 0.607.\n",
      "At iteration 2500 the loss is 0.592.\n",
      "At iteration 3000 the loss is 0.638.\n",
      "At iteration 3500 the loss is 0.622.\n",
      "\n",
      "After epoch 20 the validation accuracy is 0.367.\n",
      "After epoch 20 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.691.\n",
      "At iteration 1000 the loss is 0.648.\n",
      "At iteration 1500 the loss is 0.572.\n",
      "At iteration 2000 the loss is 0.520.\n",
      "At iteration 2500 the loss is 0.659.\n",
      "At iteration 3000 the loss is 0.637.\n",
      "At iteration 3500 the loss is 0.645.\n",
      "\n",
      "After epoch 21 the validation accuracy is 0.367.\n",
      "After epoch 21 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.596.\n",
      "At iteration 1000 the loss is 0.637.\n",
      "At iteration 1500 the loss is 0.576.\n",
      "At iteration 2000 the loss is 0.610.\n",
      "At iteration 2500 the loss is 0.631.\n",
      "At iteration 3000 the loss is 0.610.\n",
      "At iteration 3500 the loss is 0.595.\n",
      "\n",
      "After epoch 22 the validation accuracy is 0.367.\n",
      "After epoch 22 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.608.\n",
      "At iteration 1000 the loss is 0.701.\n",
      "At iteration 1500 the loss is 0.630.\n",
      "At iteration 2000 the loss is 0.636.\n",
      "At iteration 2500 the loss is 0.616.\n",
      "At iteration 3000 the loss is 0.631.\n",
      "At iteration 3500 the loss is 0.620.\n",
      "\n",
      "After epoch 23 the validation accuracy is 0.367.\n",
      "After epoch 23 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.655.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 1000 the loss is 0.593.\n",
      "At iteration 1500 the loss is 0.590.\n",
      "At iteration 2000 the loss is 0.602.\n",
      "At iteration 2500 the loss is 0.644.\n",
      "At iteration 3000 the loss is 0.611.\n",
      "At iteration 3500 the loss is 0.704.\n",
      "\n",
      "After epoch 24 the validation accuracy is 0.367.\n",
      "After epoch 24 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.541.\n",
      "At iteration 1000 the loss is 0.693.\n",
      "At iteration 1500 the loss is 0.662.\n",
      "At iteration 2000 the loss is 0.625.\n",
      "At iteration 2500 the loss is 0.633.\n",
      "At iteration 3000 the loss is 0.633.\n",
      "At iteration 3500 the loss is 0.657.\n",
      "\n",
      "After epoch 25 the validation accuracy is 0.367.\n",
      "After epoch 25 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.566.\n",
      "At iteration 1000 the loss is 0.558.\n",
      "At iteration 1500 the loss is 0.636.\n",
      "At iteration 2000 the loss is 0.718.\n",
      "At iteration 2500 the loss is 0.576.\n",
      "At iteration 3000 the loss is 0.593.\n",
      "At iteration 3500 the loss is 0.606.\n",
      "\n",
      "After epoch 26 the validation accuracy is 0.367.\n",
      "After epoch 26 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.579.\n",
      "At iteration 1000 the loss is 0.648.\n",
      "At iteration 1500 the loss is 0.577.\n",
      "At iteration 2000 the loss is 0.600.\n",
      "At iteration 2500 the loss is 0.572.\n",
      "At iteration 3000 the loss is 0.546.\n",
      "At iteration 3500 the loss is 0.667.\n",
      "\n",
      "After epoch 27 the validation accuracy is 0.367.\n",
      "After epoch 27 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.696.\n",
      "At iteration 1000 the loss is 0.631.\n",
      "At iteration 1500 the loss is 0.619.\n",
      "At iteration 2000 the loss is 0.688.\n",
      "At iteration 2500 the loss is 0.609.\n",
      "At iteration 3000 the loss is 0.668.\n",
      "At iteration 3500 the loss is 0.705.\n",
      "\n",
      "After epoch 28 the validation accuracy is 0.367.\n",
      "After epoch 28 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.582.\n",
      "At iteration 1000 the loss is 0.560.\n",
      "At iteration 1500 the loss is 0.608.\n",
      "At iteration 2000 the loss is 0.552.\n",
      "At iteration 2500 the loss is 0.671.\n",
      "At iteration 3000 the loss is 0.610.\n",
      "At iteration 3500 the loss is 0.591.\n",
      "\n",
      "After epoch 29 the validation accuracy is 0.367.\n",
      "After epoch 29 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.570.\n",
      "At iteration 1000 the loss is 0.594.\n",
      "At iteration 1500 the loss is 0.545.\n",
      "At iteration 2000 the loss is 0.620.\n",
      "At iteration 2500 the loss is 0.655.\n",
      "At iteration 3000 the loss is 0.591.\n",
      "At iteration 3500 the loss is 0.634.\n",
      "\n",
      "After epoch 30 the validation accuracy is 0.367.\n",
      "After epoch 30 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.602.\n",
      "At iteration 1000 the loss is 0.594.\n",
      "At iteration 1500 the loss is 0.665.\n",
      "At iteration 2000 the loss is 0.697.\n",
      "At iteration 2500 the loss is 0.558.\n",
      "At iteration 3000 the loss is 0.539.\n",
      "At iteration 3500 the loss is 0.638.\n",
      "\n",
      "After epoch 31 the validation accuracy is 0.367.\n",
      "After epoch 31 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.653.\n",
      "At iteration 1000 the loss is 0.720.\n",
      "At iteration 1500 the loss is 0.686.\n",
      "At iteration 2000 the loss is 0.678.\n",
      "At iteration 2500 the loss is 0.588.\n",
      "At iteration 3000 the loss is 0.562.\n",
      "At iteration 3500 the loss is 0.646.\n",
      "\n",
      "After epoch 32 the validation accuracy is 0.367.\n",
      "After epoch 32 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.669.\n",
      "At iteration 1000 the loss is 0.609.\n",
      "At iteration 1500 the loss is 0.600.\n",
      "At iteration 2000 the loss is 0.687.\n",
      "At iteration 2500 the loss is 0.591.\n",
      "At iteration 3000 the loss is 0.624.\n",
      "At iteration 3500 the loss is 0.670.\n",
      "\n",
      "After epoch 33 the validation accuracy is 0.367.\n",
      "After epoch 33 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.624.\n",
      "At iteration 1000 the loss is 0.620.\n",
      "At iteration 1500 the loss is 0.597.\n",
      "At iteration 2000 the loss is 0.635.\n",
      "At iteration 2500 the loss is 0.661.\n",
      "At iteration 3000 the loss is 0.593.\n",
      "At iteration 3500 the loss is 0.615.\n",
      "\n",
      "After epoch 34 the validation accuracy is 0.367.\n",
      "After epoch 34 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.689.\n",
      "At iteration 1000 the loss is 0.643.\n",
      "At iteration 1500 the loss is 0.647.\n",
      "At iteration 2000 the loss is 0.678.\n",
      "At iteration 2500 the loss is 0.636.\n",
      "At iteration 3000 the loss is 0.584.\n",
      "At iteration 3500 the loss is 0.573.\n",
      "\n",
      "After epoch 35 the validation accuracy is 0.367.\n",
      "After epoch 35 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.573.\n",
      "At iteration 1000 the loss is 0.608.\n",
      "At iteration 1500 the loss is 0.631.\n",
      "At iteration 2000 the loss is 0.682.\n",
      "At iteration 2500 the loss is 0.653.\n",
      "At iteration 3000 the loss is 0.750.\n",
      "At iteration 3500 the loss is 0.585.\n",
      "\n",
      "After epoch 36 the validation accuracy is 0.367.\n",
      "After epoch 36 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.649.\n",
      "At iteration 1000 the loss is 0.648.\n",
      "At iteration 1500 the loss is 0.636.\n",
      "At iteration 2000 the loss is 0.559.\n",
      "At iteration 2500 the loss is 0.684.\n",
      "At iteration 3000 the loss is 0.702.\n",
      "At iteration 3500 the loss is 0.639.\n",
      "\n",
      "After epoch 37 the validation accuracy is 0.367.\n",
      "After epoch 37 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.618.\n",
      "At iteration 1000 the loss is 0.567.\n",
      "At iteration 1500 the loss is 0.651.\n",
      "At iteration 2000 the loss is 0.667.\n",
      "At iteration 2500 the loss is 0.562.\n",
      "At iteration 3000 the loss is 0.683.\n",
      "At iteration 3500 the loss is 0.612.\n",
      "\n",
      "After epoch 38 the validation accuracy is 0.367.\n",
      "After epoch 38 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.600.\n",
      "At iteration 1000 the loss is 0.676.\n",
      "At iteration 1500 the loss is 0.613.\n",
      "At iteration 2000 the loss is 0.624.\n",
      "At iteration 2500 the loss is 0.630.\n",
      "At iteration 3000 the loss is 0.591.\n",
      "At iteration 3500 the loss is 0.662.\n",
      "\n",
      "After epoch 39 the validation accuracy is 0.367.\n",
      "After epoch 39 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.601.\n",
      "At iteration 1000 the loss is 0.584.\n",
      "At iteration 1500 the loss is 0.586.\n",
      "At iteration 2000 the loss is 0.708.\n",
      "At iteration 2500 the loss is 0.583.\n",
      "At iteration 3000 the loss is 0.601.\n",
      "At iteration 3500 the loss is 0.727.\n",
      "\n",
      "After epoch 40 the validation accuracy is 0.367.\n",
      "After epoch 40 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.577.\n",
      "At iteration 1000 the loss is 0.655.\n",
      "At iteration 1500 the loss is 0.629.\n",
      "At iteration 2000 the loss is 0.591.\n",
      "At iteration 2500 the loss is 0.692.\n",
      "At iteration 3000 the loss is 0.632.\n",
      "At iteration 3500 the loss is 0.690.\n",
      "\n",
      "After epoch 41 the validation accuracy is 0.367.\n",
      "After epoch 41 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.679.\n",
      "At iteration 1000 the loss is 0.619.\n",
      "At iteration 1500 the loss is 0.677.\n",
      "At iteration 2000 the loss is 0.640.\n",
      "At iteration 2500 the loss is 0.625.\n",
      "At iteration 3000 the loss is 0.596.\n",
      "At iteration 3500 the loss is 0.593.\n",
      "\n",
      "After epoch 42 the validation accuracy is 0.367.\n",
      "After epoch 42 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.611.\n",
      "At iteration 1000 the loss is 0.620.\n",
      "At iteration 1500 the loss is 0.609.\n",
      "At iteration 2000 the loss is 0.632.\n",
      "At iteration 2500 the loss is 0.750.\n",
      "At iteration 3000 the loss is 0.571.\n",
      "At iteration 3500 the loss is 0.572.\n",
      "\n",
      "After epoch 43 the validation accuracy is 0.367.\n",
      "After epoch 43 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.604.\n",
      "At iteration 1000 the loss is 0.613.\n",
      "At iteration 1500 the loss is 0.607.\n",
      "At iteration 2000 the loss is 0.661.\n",
      "At iteration 2500 the loss is 0.629.\n",
      "At iteration 3000 the loss is 0.716.\n",
      "At iteration 3500 the loss is 0.526.\n",
      "\n",
      "After epoch 44 the validation accuracy is 0.367.\n",
      "After epoch 44 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.614.\n",
      "At iteration 1000 the loss is 0.733.\n",
      "At iteration 1500 the loss is 0.600.\n",
      "At iteration 2000 the loss is 0.660.\n",
      "At iteration 2500 the loss is 0.516.\n",
      "At iteration 3000 the loss is 0.642.\n",
      "At iteration 3500 the loss is 0.611.\n",
      "\n",
      "After epoch 45 the validation accuracy is 0.367.\n",
      "After epoch 45 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.608.\n",
      "At iteration 1000 the loss is 0.651.\n",
      "At iteration 1500 the loss is 0.639.\n",
      "At iteration 2000 the loss is 0.697.\n",
      "At iteration 2500 the loss is 0.657.\n",
      "At iteration 3000 the loss is 0.624.\n",
      "At iteration 3500 the loss is 0.629.\n",
      "\n",
      "After epoch 46 the validation accuracy is 0.367.\n",
      "After epoch 46 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.609.\n",
      "At iteration 1000 the loss is 0.547.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 1500 the loss is 0.626.\n",
      "At iteration 2000 the loss is 0.577.\n",
      "At iteration 2500 the loss is 0.643.\n",
      "At iteration 3000 the loss is 0.633.\n",
      "At iteration 3500 the loss is 0.593.\n",
      "\n",
      "After epoch 47 the validation accuracy is 0.367.\n",
      "After epoch 47 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.572.\n",
      "At iteration 1000 the loss is 0.636.\n",
      "At iteration 1500 the loss is 0.590.\n",
      "At iteration 2000 the loss is 0.594.\n",
      "At iteration 2500 the loss is 0.641.\n",
      "At iteration 3000 the loss is 0.717.\n",
      "At iteration 3500 the loss is 0.594.\n",
      "\n",
      "After epoch 48 the validation accuracy is 0.367.\n",
      "After epoch 48 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.639.\n",
      "At iteration 1000 the loss is 0.638.\n",
      "At iteration 1500 the loss is 0.639.\n",
      "At iteration 2000 the loss is 0.677.\n",
      "At iteration 2500 the loss is 0.641.\n",
      "At iteration 3000 the loss is 0.621.\n",
      "At iteration 3500 the loss is 0.612.\n",
      "\n",
      "After epoch 49 the validation accuracy is 0.367.\n",
      "After epoch 49 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.582.\n",
      "At iteration 1000 the loss is 0.671.\n",
      "At iteration 1500 the loss is 0.599.\n",
      "At iteration 2000 the loss is 0.671.\n",
      "At iteration 2500 the loss is 0.603.\n",
      "At iteration 3000 the loss is 0.598.\n",
      "At iteration 3500 the loss is 0.674.\n",
      "\n",
      "After epoch 50 the validation accuracy is 0.367.\n",
      "After epoch 50 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.729.\n",
      "At iteration 1000 the loss is 0.660.\n",
      "At iteration 1500 the loss is 0.673.\n",
      "At iteration 2000 the loss is 0.695.\n",
      "At iteration 2500 the loss is 0.617.\n",
      "At iteration 3000 the loss is 0.602.\n",
      "At iteration 3500 the loss is 0.640.\n",
      "\n",
      "After epoch 51 the validation accuracy is 0.367.\n",
      "After epoch 51 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.574.\n",
      "At iteration 1000 the loss is 0.611.\n",
      "At iteration 1500 the loss is 0.622.\n",
      "At iteration 2000 the loss is 0.729.\n",
      "At iteration 2500 the loss is 0.626.\n",
      "At iteration 3000 the loss is 0.558.\n",
      "At iteration 3500 the loss is 0.614.\n",
      "\n",
      "After epoch 52 the validation accuracy is 0.367.\n",
      "After epoch 52 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.638.\n",
      "At iteration 1000 the loss is 0.609.\n",
      "At iteration 1500 the loss is 0.672.\n",
      "At iteration 2000 the loss is 0.631.\n",
      "At iteration 2500 the loss is 0.608.\n",
      "At iteration 3000 the loss is 0.657.\n",
      "At iteration 3500 the loss is 0.670.\n",
      "\n",
      "After epoch 53 the validation accuracy is 0.367.\n",
      "After epoch 53 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.632.\n",
      "At iteration 1000 the loss is 0.625.\n",
      "At iteration 1500 the loss is 0.574.\n",
      "At iteration 2000 the loss is 0.658.\n",
      "At iteration 2500 the loss is 0.626.\n",
      "At iteration 3000 the loss is 0.620.\n",
      "At iteration 3500 the loss is 0.610.\n",
      "\n",
      "After epoch 54 the validation accuracy is 0.367.\n",
      "After epoch 54 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.626.\n",
      "At iteration 1000 the loss is 0.546.\n",
      "At iteration 1500 the loss is 0.573.\n",
      "At iteration 2000 the loss is 0.679.\n",
      "At iteration 2500 the loss is 0.657.\n",
      "At iteration 3000 the loss is 0.595.\n",
      "At iteration 3500 the loss is 0.572.\n",
      "\n",
      "After epoch 55 the validation accuracy is 0.367.\n",
      "After epoch 55 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.649.\n",
      "At iteration 1000 the loss is 0.585.\n",
      "At iteration 1500 the loss is 0.607.\n",
      "At iteration 2000 the loss is 0.636.\n",
      "At iteration 2500 the loss is 0.692.\n",
      "At iteration 3000 the loss is 0.623.\n",
      "At iteration 3500 the loss is 0.578.\n",
      "\n",
      "After epoch 56 the validation accuracy is 0.367.\n",
      "After epoch 56 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.546.\n",
      "At iteration 1000 the loss is 0.628.\n",
      "At iteration 1500 the loss is 0.633.\n",
      "At iteration 2000 the loss is 0.553.\n",
      "At iteration 2500 the loss is 0.591.\n",
      "At iteration 3000 the loss is 0.609.\n",
      "At iteration 3500 the loss is 0.665.\n",
      "\n",
      "After epoch 57 the validation accuracy is 0.367.\n",
      "After epoch 57 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.628.\n",
      "At iteration 1000 the loss is 0.640.\n",
      "At iteration 1500 the loss is 0.579.\n",
      "At iteration 2000 the loss is 0.597.\n",
      "At iteration 2500 the loss is 0.553.\n",
      "At iteration 3000 the loss is 0.576.\n",
      "At iteration 3500 the loss is 0.605.\n",
      "\n",
      "After epoch 58 the validation accuracy is 0.367.\n",
      "After epoch 58 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.610.\n",
      "At iteration 1000 the loss is 0.558.\n",
      "At iteration 1500 the loss is 0.689.\n",
      "At iteration 2000 the loss is 0.641.\n",
      "At iteration 2500 the loss is 0.651.\n",
      "At iteration 3000 the loss is 0.602.\n",
      "At iteration 3500 the loss is 0.608.\n",
      "\n",
      "After epoch 59 the validation accuracy is 0.368.\n",
      "After epoch 59 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.602.\n",
      "At iteration 1000 the loss is 0.629.\n",
      "At iteration 1500 the loss is 0.563.\n",
      "At iteration 2000 the loss is 0.594.\n",
      "At iteration 2500 the loss is 0.552.\n",
      "At iteration 3000 the loss is 0.621.\n",
      "At iteration 3500 the loss is 0.626.\n",
      "\n",
      "After epoch 60 the validation accuracy is 0.368.\n",
      "After epoch 60 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.597.\n",
      "At iteration 1000 the loss is 0.617.\n",
      "At iteration 1500 the loss is 0.700.\n",
      "At iteration 2000 the loss is 0.706.\n",
      "At iteration 2500 the loss is 0.593.\n",
      "At iteration 3000 the loss is 0.587.\n",
      "At iteration 3500 the loss is 0.567.\n",
      "\n",
      "After epoch 61 the validation accuracy is 0.368.\n",
      "After epoch 61 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.585.\n",
      "At iteration 1000 the loss is 0.686.\n",
      "At iteration 1500 the loss is 0.609.\n",
      "At iteration 2000 the loss is 0.650.\n",
      "At iteration 2500 the loss is 0.608.\n",
      "At iteration 3000 the loss is 0.650.\n",
      "At iteration 3500 the loss is 0.635.\n",
      "\n",
      "After epoch 62 the validation accuracy is 0.368.\n",
      "After epoch 62 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.706.\n",
      "At iteration 1000 the loss is 0.623.\n",
      "At iteration 1500 the loss is 0.608.\n",
      "At iteration 2000 the loss is 0.656.\n",
      "At iteration 2500 the loss is 0.620.\n",
      "At iteration 3000 the loss is 0.562.\n",
      "At iteration 3500 the loss is 0.574.\n",
      "\n",
      "After epoch 63 the validation accuracy is 0.368.\n",
      "After epoch 63 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.728.\n",
      "At iteration 1000 the loss is 0.691.\n",
      "At iteration 1500 the loss is 0.648.\n",
      "At iteration 2000 the loss is 0.662.\n",
      "At iteration 2500 the loss is 0.648.\n",
      "At iteration 3000 the loss is 0.676.\n",
      "At iteration 3500 the loss is 0.575.\n",
      "\n",
      "After epoch 64 the validation accuracy is 0.368.\n",
      "After epoch 64 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.628.\n",
      "At iteration 1000 the loss is 0.674.\n",
      "At iteration 1500 the loss is 0.569.\n",
      "At iteration 2000 the loss is 0.612.\n",
      "At iteration 2500 the loss is 0.581.\n",
      "At iteration 3000 the loss is 0.700.\n",
      "At iteration 3500 the loss is 0.639.\n",
      "\n",
      "After epoch 65 the validation accuracy is 0.368.\n",
      "After epoch 65 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.628.\n",
      "At iteration 1000 the loss is 0.592.\n",
      "At iteration 1500 the loss is 0.627.\n",
      "At iteration 2000 the loss is 0.577.\n",
      "At iteration 2500 the loss is 0.565.\n",
      "At iteration 3000 the loss is 0.609.\n",
      "At iteration 3500 the loss is 0.626.\n",
      "\n",
      "After epoch 66 the validation accuracy is 0.368.\n",
      "After epoch 66 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.656.\n",
      "At iteration 1000 the loss is 0.631.\n",
      "At iteration 1500 the loss is 0.638.\n",
      "At iteration 2000 the loss is 0.564.\n",
      "At iteration 2500 the loss is 0.630.\n",
      "At iteration 3000 the loss is 0.586.\n",
      "At iteration 3500 the loss is 0.628.\n",
      "\n",
      "After epoch 67 the validation accuracy is 0.368.\n",
      "After epoch 67 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.698.\n",
      "At iteration 1000 the loss is 0.584.\n",
      "At iteration 1500 the loss is 0.651.\n",
      "At iteration 2000 the loss is 0.589.\n",
      "At iteration 2500 the loss is 0.680.\n",
      "At iteration 3000 the loss is 0.674.\n",
      "At iteration 3500 the loss is 0.565.\n",
      "\n",
      "After epoch 68 the validation accuracy is 0.368.\n",
      "After epoch 68 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.628.\n",
      "At iteration 1000 the loss is 0.680.\n",
      "At iteration 1500 the loss is 0.670.\n",
      "At iteration 2000 the loss is 0.734.\n",
      "At iteration 2500 the loss is 0.619.\n",
      "At iteration 3000 the loss is 0.646.\n",
      "At iteration 3500 the loss is 0.730.\n",
      "\n",
      "After epoch 69 the validation accuracy is 0.368.\n",
      "After epoch 69 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.634.\n",
      "At iteration 1000 the loss is 0.616.\n",
      "At iteration 1500 the loss is 0.658.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 2000 the loss is 0.620.\n",
      "At iteration 2500 the loss is 0.643.\n",
      "At iteration 3000 the loss is 0.611.\n",
      "At iteration 3500 the loss is 0.626.\n",
      "\n",
      "After epoch 70 the validation accuracy is 0.368.\n",
      "After epoch 70 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.574.\n",
      "At iteration 1000 the loss is 0.618.\n",
      "At iteration 1500 the loss is 0.562.\n",
      "At iteration 2000 the loss is 0.617.\n",
      "At iteration 2500 the loss is 0.637.\n",
      "At iteration 3000 the loss is 0.630.\n",
      "At iteration 3500 the loss is 0.638.\n",
      "\n",
      "After epoch 71 the validation accuracy is 0.368.\n",
      "After epoch 71 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.571.\n",
      "At iteration 1000 the loss is 0.644.\n",
      "At iteration 1500 the loss is 0.598.\n",
      "At iteration 2000 the loss is 0.598.\n",
      "At iteration 2500 the loss is 0.649.\n",
      "At iteration 3000 the loss is 0.584.\n",
      "At iteration 3500 the loss is 0.657.\n",
      "\n",
      "After epoch 72 the validation accuracy is 0.368.\n",
      "After epoch 72 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.596.\n",
      "At iteration 1000 the loss is 0.526.\n",
      "At iteration 1500 the loss is 0.622.\n",
      "At iteration 2000 the loss is 0.717.\n",
      "At iteration 2500 the loss is 0.669.\n",
      "At iteration 3000 the loss is 0.597.\n",
      "At iteration 3500 the loss is 0.666.\n",
      "\n",
      "After epoch 73 the validation accuracy is 0.368.\n",
      "After epoch 73 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.630.\n",
      "At iteration 1000 the loss is 0.628.\n",
      "At iteration 1500 the loss is 0.583.\n",
      "At iteration 2000 the loss is 0.602.\n",
      "At iteration 2500 the loss is 0.651.\n",
      "At iteration 3000 the loss is 0.700.\n",
      "At iteration 3500 the loss is 0.580.\n",
      "\n",
      "After epoch 74 the validation accuracy is 0.368.\n",
      "After epoch 74 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.614.\n",
      "At iteration 1000 the loss is 0.614.\n",
      "At iteration 1500 the loss is 0.657.\n",
      "At iteration 2000 the loss is 0.628.\n",
      "At iteration 2500 the loss is 0.624.\n",
      "At iteration 3000 the loss is 0.533.\n",
      "At iteration 3500 the loss is 0.605.\n",
      "\n",
      "After epoch 75 the validation accuracy is 0.368.\n",
      "After epoch 75 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.628.\n",
      "At iteration 1000 the loss is 0.580.\n",
      "At iteration 1500 the loss is 0.631.\n",
      "At iteration 2000 the loss is 0.581.\n",
      "At iteration 2500 the loss is 0.635.\n",
      "At iteration 3000 the loss is 0.588.\n",
      "At iteration 3500 the loss is 0.633.\n",
      "\n",
      "After epoch 76 the validation accuracy is 0.368.\n",
      "After epoch 76 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.635.\n",
      "At iteration 1000 the loss is 0.620.\n",
      "At iteration 1500 the loss is 0.623.\n",
      "At iteration 2000 the loss is 0.628.\n",
      "At iteration 2500 the loss is 0.664.\n",
      "At iteration 3000 the loss is 0.640.\n",
      "At iteration 3500 the loss is 0.635.\n",
      "\n",
      "After epoch 77 the validation accuracy is 0.368.\n",
      "After epoch 77 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.642.\n",
      "At iteration 1000 the loss is 0.653.\n",
      "At iteration 1500 the loss is 0.682.\n",
      "At iteration 2000 the loss is 0.624.\n",
      "At iteration 2500 the loss is 0.597.\n",
      "At iteration 3000 the loss is 0.583.\n",
      "At iteration 3500 the loss is 0.637.\n",
      "\n",
      "After epoch 78 the validation accuracy is 0.368.\n",
      "After epoch 78 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.673.\n",
      "At iteration 1000 the loss is 0.571.\n",
      "At iteration 1500 the loss is 0.676.\n",
      "At iteration 2000 the loss is 0.691.\n",
      "At iteration 2500 the loss is 0.609.\n",
      "At iteration 3000 the loss is 0.640.\n",
      "At iteration 3500 the loss is 0.616.\n",
      "\n",
      "After epoch 79 the validation accuracy is 0.368.\n",
      "After epoch 79 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.621.\n",
      "At iteration 1000 the loss is 0.617.\n",
      "At iteration 1500 the loss is 0.591.\n",
      "At iteration 2000 the loss is 0.587.\n",
      "At iteration 2500 the loss is 0.682.\n",
      "At iteration 3000 the loss is 0.592.\n",
      "At iteration 3500 the loss is 0.675.\n",
      "\n",
      "After epoch 80 the validation accuracy is 0.368.\n",
      "After epoch 80 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.608.\n",
      "At iteration 1000 the loss is 0.638.\n",
      "At iteration 1500 the loss is 0.555.\n",
      "At iteration 2000 the loss is 0.629.\n",
      "At iteration 2500 the loss is 0.692.\n",
      "At iteration 3000 the loss is 0.609.\n",
      "At iteration 3500 the loss is 0.591.\n",
      "\n",
      "After epoch 81 the validation accuracy is 0.368.\n",
      "After epoch 81 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.671.\n",
      "At iteration 1000 the loss is 0.666.\n",
      "At iteration 1500 the loss is 0.594.\n",
      "At iteration 2000 the loss is 0.656.\n",
      "At iteration 2500 the loss is 0.630.\n",
      "At iteration 3000 the loss is 0.601.\n",
      "At iteration 3500 the loss is 0.622.\n",
      "\n",
      "After epoch 82 the validation accuracy is 0.368.\n",
      "After epoch 82 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.713.\n",
      "At iteration 1000 the loss is 0.652.\n",
      "At iteration 1500 the loss is 0.559.\n",
      "At iteration 2000 the loss is 0.629.\n",
      "At iteration 2500 the loss is 0.637.\n",
      "At iteration 3000 the loss is 0.569.\n",
      "At iteration 3500 the loss is 0.594.\n",
      "\n",
      "After epoch 83 the validation accuracy is 0.368.\n",
      "After epoch 83 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.606.\n",
      "At iteration 1000 the loss is 0.641.\n",
      "At iteration 1500 the loss is 0.625.\n",
      "At iteration 2000 the loss is 0.599.\n",
      "At iteration 2500 the loss is 0.663.\n",
      "At iteration 3000 the loss is 0.545.\n",
      "At iteration 3500 the loss is 0.645.\n",
      "\n",
      "After epoch 84 the validation accuracy is 0.368.\n",
      "After epoch 84 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.628.\n",
      "At iteration 1000 the loss is 0.607.\n",
      "At iteration 1500 the loss is 0.620.\n",
      "At iteration 2000 the loss is 0.636.\n",
      "At iteration 2500 the loss is 0.676.\n",
      "At iteration 3000 the loss is 0.679.\n",
      "At iteration 3500 the loss is 0.627.\n",
      "\n",
      "After epoch 85 the validation accuracy is 0.368.\n",
      "After epoch 85 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.705.\n",
      "At iteration 1000 the loss is 0.586.\n",
      "At iteration 1500 the loss is 0.609.\n",
      "At iteration 2000 the loss is 0.654.\n",
      "At iteration 2500 the loss is 0.628.\n",
      "At iteration 3000 the loss is 0.571.\n",
      "At iteration 3500 the loss is 0.667.\n",
      "\n",
      "After epoch 86 the validation accuracy is 0.368.\n",
      "After epoch 86 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.620.\n",
      "At iteration 1000 the loss is 0.611.\n",
      "At iteration 1500 the loss is 0.613.\n",
      "At iteration 2000 the loss is 0.628.\n",
      "At iteration 2500 the loss is 0.606.\n",
      "At iteration 3000 the loss is 0.582.\n",
      "At iteration 3500 the loss is 0.637.\n",
      "\n",
      "After epoch 87 the validation accuracy is 0.368.\n",
      "After epoch 87 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.712.\n",
      "At iteration 1000 the loss is 0.540.\n",
      "At iteration 1500 the loss is 0.699.\n",
      "At iteration 2000 the loss is 0.602.\n",
      "At iteration 2500 the loss is 0.631.\n",
      "At iteration 3000 the loss is 0.654.\n",
      "At iteration 3500 the loss is 0.651.\n",
      "\n",
      "After epoch 88 the validation accuracy is 0.368.\n",
      "After epoch 88 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.621.\n",
      "At iteration 1000 the loss is 0.653.\n",
      "At iteration 1500 the loss is 0.587.\n",
      "At iteration 2000 the loss is 0.650.\n",
      "At iteration 2500 the loss is 0.581.\n",
      "At iteration 3000 the loss is 0.641.\n",
      "At iteration 3500 the loss is 0.601.\n",
      "\n",
      "After epoch 89 the validation accuracy is 0.368.\n",
      "After epoch 89 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.629.\n",
      "At iteration 1000 the loss is 0.543.\n",
      "At iteration 1500 the loss is 0.646.\n",
      "At iteration 2000 the loss is 0.660.\n",
      "At iteration 2500 the loss is 0.672.\n",
      "At iteration 3000 the loss is 0.557.\n",
      "At iteration 3500 the loss is 0.673.\n",
      "\n",
      "After epoch 90 the validation accuracy is 0.368.\n",
      "After epoch 90 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.579.\n",
      "At iteration 1000 the loss is 0.605.\n",
      "At iteration 1500 the loss is 0.624.\n",
      "At iteration 2000 the loss is 0.599.\n",
      "At iteration 2500 the loss is 0.632.\n",
      "At iteration 3000 the loss is 0.496.\n",
      "At iteration 3500 the loss is 0.607.\n",
      "\n",
      "After epoch 91 the validation accuracy is 0.368.\n",
      "After epoch 91 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.612.\n",
      "At iteration 1000 the loss is 0.642.\n",
      "At iteration 1500 the loss is 0.618.\n",
      "At iteration 2000 the loss is 0.582.\n",
      "At iteration 2500 the loss is 0.519.\n",
      "At iteration 3000 the loss is 0.602.\n",
      "At iteration 3500 the loss is 0.607.\n",
      "\n",
      "After epoch 92 the validation accuracy is 0.368.\n",
      "After epoch 92 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.731.\n",
      "At iteration 1000 the loss is 0.559.\n",
      "At iteration 1500 the loss is 0.687.\n",
      "At iteration 2000 the loss is 0.604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 2500 the loss is 0.598.\n",
      "At iteration 3000 the loss is 0.730.\n",
      "At iteration 3500 the loss is 0.617.\n",
      "\n",
      "After epoch 93 the validation accuracy is 0.368.\n",
      "After epoch 93 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.639.\n",
      "At iteration 1000 the loss is 0.519.\n",
      "At iteration 1500 the loss is 0.566.\n",
      "At iteration 2000 the loss is 0.622.\n",
      "At iteration 2500 the loss is 0.672.\n",
      "At iteration 3000 the loss is 0.663.\n",
      "At iteration 3500 the loss is 0.550.\n",
      "\n",
      "After epoch 94 the validation accuracy is 0.368.\n",
      "After epoch 94 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.718.\n",
      "At iteration 1000 the loss is 0.590.\n",
      "At iteration 1500 the loss is 0.635.\n",
      "At iteration 2000 the loss is 0.732.\n",
      "At iteration 2500 the loss is 0.602.\n",
      "At iteration 3000 the loss is 0.642.\n",
      "At iteration 3500 the loss is 0.664.\n",
      "\n",
      "After epoch 95 the validation accuracy is 0.368.\n",
      "After epoch 95 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.633.\n",
      "At iteration 1000 the loss is 0.641.\n",
      "At iteration 1500 the loss is 0.598.\n",
      "At iteration 2000 the loss is 0.603.\n",
      "At iteration 2500 the loss is 0.725.\n",
      "At iteration 3000 the loss is 0.593.\n",
      "At iteration 3500 the loss is 0.678.\n",
      "\n",
      "After epoch 96 the validation accuracy is 0.368.\n",
      "After epoch 96 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.699.\n",
      "At iteration 1000 the loss is 0.626.\n",
      "At iteration 1500 the loss is 0.575.\n",
      "At iteration 2000 the loss is 0.618.\n",
      "At iteration 2500 the loss is 0.689.\n",
      "At iteration 3000 the loss is 0.716.\n",
      "At iteration 3500 the loss is 0.679.\n",
      "\n",
      "After epoch 97 the validation accuracy is 0.368.\n",
      "After epoch 97 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.688.\n",
      "At iteration 1000 the loss is 0.642.\n",
      "At iteration 1500 the loss is 0.601.\n",
      "At iteration 2000 the loss is 0.591.\n",
      "At iteration 2500 the loss is 0.698.\n",
      "At iteration 3000 the loss is 0.643.\n",
      "At iteration 3500 the loss is 0.615.\n",
      "\n",
      "After epoch 98 the validation accuracy is 0.368.\n",
      "After epoch 98 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.605.\n",
      "At iteration 1000 the loss is 0.659.\n",
      "At iteration 1500 the loss is 0.640.\n",
      "At iteration 2000 the loss is 0.598.\n",
      "At iteration 2500 the loss is 0.612.\n",
      "At iteration 3000 the loss is 0.594.\n",
      "At iteration 3500 the loss is 0.515.\n",
      "\n",
      "After epoch 99 the validation accuracy is 0.368.\n",
      "After epoch 99 the training accuracy is 0.672.\n",
      "\n",
      "At iteration 500 the loss is 0.615.\n",
      "At iteration 1000 the loss is 0.737.\n",
      "At iteration 1500 the loss is 0.673.\n",
      "At iteration 2000 the loss is 0.638.\n",
      "At iteration 2500 the loss is 0.618.\n",
      "At iteration 3000 the loss is 0.536.\n",
      "At iteration 3500 the loss is 0.571.\n",
      "\n",
      "After epoch 100 the validation accuracy is 0.368.\n",
      "After epoch 100 the training accuracy is 0.672.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100 # epoch\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "accuracies=[]\n",
    "train_accuracies=[]\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train_an_epoch(train_dataloader)\n",
    "    accuracy = get_accuracy(valid_dataloader)\n",
    "    train_accuracy = get_accuracy(train_dataloader)\n",
    "    accuracies.append(accuracy)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    time_taken = time.time() - epoch_start_time\n",
    "    print()\n",
    "    print(f'After epoch {epoch} the validation accuracy is {accuracy:.3f}.')\n",
    "    print(f'After epoch {epoch} the training accuracy is {train_accuracy:.3f}.')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DAN and Logistic Regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
